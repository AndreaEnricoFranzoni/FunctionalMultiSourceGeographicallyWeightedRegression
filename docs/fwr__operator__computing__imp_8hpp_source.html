<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.13.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>fdagwr: src/integration/fwr_operator_computing_imp.hpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
  $(function() { init_search(); });
/* @license-end */
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">fdagwr
   </div>
  </td>
    <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <span id="MSearchSelect"                onmouseover="return searchBox.OnSearchSelectShow()"                onmouseout="return searchBox.OnSearchSelectHide()">&#160;</span>
          <input type="text" id="MSearchField" value="" placeholder="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.svg" alt=""/></a>
          </span>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.13.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(0); });
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){initNavTree('fwr__operator__computing__imp_8hpp_source.html',''); initResizable(true); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="headertitle"><div class="title">fwr_operator_computing_imp.hpp</div></div>
</div><!--header-->
<div class="contents">
<a href="fwr__operator__computing__imp_8hpp.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a id="l00001" name="l00001"></a><span class="lineno">    1</span><span class="comment">// Copyright (c) 2025 Andrea Enrico Franzoni (andreaenrico.franzoni@gmail.com)</span></div>
<div class="line"><a id="l00002" name="l00002"></a><span class="lineno">    2</span><span class="comment">//</span></div>
<div class="line"><a id="l00003" name="l00003"></a><span class="lineno">    3</span><span class="comment">// This file is part of fdagwr</span></div>
<div class="line"><a id="l00004" name="l00004"></a><span class="lineno">    4</span><span class="comment">//</span></div>
<div class="line"><a id="l00005" name="l00005"></a><span class="lineno">    5</span><span class="comment">// Permission is hereby granted, free of charge, to any person obtaining a copy</span></div>
<div class="line"><a id="l00006" name="l00006"></a><span class="lineno">    6</span><span class="comment">// of fdagwr and associated documentation files (the fdagwr software), to deal</span></div>
<div class="line"><a id="l00007" name="l00007"></a><span class="lineno">    7</span><span class="comment">// fdagwr without restriction, including without limitation the rights</span></div>
<div class="line"><a id="l00008" name="l00008"></a><span class="lineno">    8</span><span class="comment">// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell</span></div>
<div class="line"><a id="l00009" name="l00009"></a><span class="lineno">    9</span><span class="comment">// copies of fdagwr, and to permit persons to whom fdagwr is</span></div>
<div class="line"><a id="l00010" name="l00010"></a><span class="lineno">   10</span><span class="comment">// furnished to do so, subject to the following conditions:</span></div>
<div class="line"><a id="l00011" name="l00011"></a><span class="lineno">   11</span><span class="comment">//</span></div>
<div class="line"><a id="l00012" name="l00012"></a><span class="lineno">   12</span><span class="comment">// fdagwr IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR</span></div>
<div class="line"><a id="l00013" name="l00013"></a><span class="lineno">   13</span><span class="comment">// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,</span></div>
<div class="line"><a id="l00014" name="l00014"></a><span class="lineno">   14</span><span class="comment">// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE</span></div>
<div class="line"><a id="l00015" name="l00015"></a><span class="lineno">   15</span><span class="comment">// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER</span></div>
<div class="line"><a id="l00016" name="l00016"></a><span class="lineno">   16</span><span class="comment">// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,</span></div>
<div class="line"><a id="l00017" name="l00017"></a><span class="lineno">   17</span><span class="comment">// OUT OF OR IN CONNECTION WITH fdagwr OR THE USE OR OTHER DEALINGS IN</span></div>
<div class="line"><a id="l00018" name="l00018"></a><span class="lineno">   18</span><span class="comment">// fdagwr.</span></div>
<div class="line"><a id="l00019" name="l00019"></a><span class="lineno">   19</span> </div>
<div class="line"><a id="l00020" name="l00020"></a><span class="lineno">   20</span> </div>
<div class="line"><a id="l00021" name="l00021"></a><span class="lineno">   21</span><span class="preprocessor">#include &quot;<a class="code" href="fwr__operator__computing_8hpp.html">fwr_operator_computing.hpp</a>&quot;</span></div>
<div class="line"><a id="l00022" name="l00022"></a><span class="lineno">   22</span> </div>
<div class="line"><a id="l00023" name="l00023"></a><span class="lineno">   23</span> </div>
<div class="line"><a id="l00024" name="l00024"></a><span class="lineno">   24</span></div>
<div class="line"><a id="l00030" name="l00030"></a><span class="lineno">   30</span> </div>
<div class="line"><a id="l00031" name="l00031"></a><span class="lineno">   31</span> </div>
<div class="line"><a id="l00032" name="l00032"></a><span class="lineno">   32</span></div>
<div class="line"><a id="l00044" name="l00044"></a><span class="lineno">   44</span><span class="keyword">template</span>&lt; <span class="keyword">typename</span> INPUT, <span class="keyword">typename</span> OUTPUT &gt;</div>
<div class="line"><a id="l00045" name="l00045"></a><span class="lineno">   45</span>    <span class="keyword">requires</span> (std::integral&lt;INPUT&gt; || std::floating_point&lt;INPUT&gt;)  &amp;&amp;  (std::integral&lt;OUTPUT&gt; || std::floating_point&lt;OUTPUT&gt;)</div>
<div class="line"><a id="l00046" name="l00046"></a><span class="lineno">   46</span>std::vector&lt; Eigen::PartialPivLU&lt;FDAGWR_TRAITS::Dense_Matrix&gt; &gt;</div>
<div class="foldopen" id="foldopen00047" data-start="{" data-end="}">
<div class="line"><a id="l00047" name="l00047"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#a634f00fe47b21671fb008f732eb7ec89">   47</a></span><a class="code hl_function" href="classfwr__operator__computing.html#a634f00fe47b21671fb008f732eb7ec89">fwr_operator_computing&lt;INPUT,OUTPUT&gt;::compute_penalty</a>(<span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix__sparse.html">functional_matrix_sparse&lt;INPUT,OUTPUT&gt;</a> &amp;base_t,</div>
<div class="line"><a id="l00048" name="l00048"></a><span class="lineno">   48</span>                                                      <span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> &amp;X_t,</div>
<div class="line"><a id="l00049" name="l00049"></a><span class="lineno">   49</span>                                                      <span class="keyword">const</span> std::vector&lt; <a class="code hl_class" href="classfunctional__matrix__diagonal.html">functional_matrix_diagonal&lt;INPUT,OUTPUT&gt;</a> &gt; &amp;W,</div>
<div class="line"><a id="l00050" name="l00050"></a><span class="lineno">   50</span>                                                      <span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> &amp;X,</div>
<div class="line"><a id="l00051" name="l00051"></a><span class="lineno">   51</span>                                                      <span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix__sparse.html">functional_matrix_sparse&lt;INPUT,OUTPUT&gt;</a> &amp;base,</div>
<div class="line"><a id="l00052" name="l00052"></a><span class="lineno">   52</span>                                                      <span class="keyword">const</span> <a class="code hl_typedef" href="struct_f_d_a_g_w_r___t_r_a_i_t_s.html#a3c0ac6887d94bffa71939fba3c05fb98">FDAGWR_TRAITS::Sparse_Matrix</a> &amp;R)<span class="keyword"></span></div>
<div class="line"><a id="l00053" name="l00053"></a><span class="lineno">   53</span><span class="keyword">const</span></div>
<div class="line"><a id="l00054" name="l00054"></a><span class="lineno">   54</span><span class="keyword"></span>{</div>
<div class="line"><a id="l00055" name="l00055"></a><span class="lineno">   55</span>    <span class="comment">//the vector contains factorization of the matrix</span></div>
<div class="line"><a id="l00056" name="l00056"></a><span class="lineno">   56</span>    std::vector&lt; Eigen::PartialPivLU&lt;FDAGWR_TRAITS::Dense_Matrix&gt; &gt; penalty;</div>
<div class="line"><a id="l00057" name="l00057"></a><span class="lineno">   57</span>    penalty.resize(W.size());</div>
<div class="line"><a id="l00058" name="l00058"></a><span class="lineno">   58</span> </div>
<div class="line"><a id="l00059" name="l00059"></a><span class="lineno">   59</span>    <a class="code hl_typedef" href="struct_f_d_a_g_w_r___t_r_a_i_t_s.html#a7480032013388cae40a69abf8d4ba297">FDAGWR_TRAITS::Dense_Matrix</a> _R_ = <a class="code hl_typedef" href="struct_f_d_a_g_w_r___t_r_a_i_t_s.html#a7480032013388cae40a69abf8d4ba297">FDAGWR_TRAITS::Dense_Matrix</a>(R);   <span class="comment">//necessary to compute the sum later</span></div>
<div class="line"><a id="l00060" name="l00060"></a><span class="lineno">   60</span> </div>
<div class="line"><a id="l00061" name="l00061"></a><span class="lineno">   61</span><span class="preprocessor">#ifdef _OPENMP</span></div>
<div class="line"><a id="l00062" name="l00062"></a><span class="lineno">   62</span><span class="preprocessor">#pragma omp parallel for shared(penalty,base,base_t,X,X_t,W,_R_,m_number_threads) num_threads(m_number_threads)</span></div>
<div class="line"><a id="l00063" name="l00063"></a><span class="lineno">   63</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l00064" name="l00064"></a><span class="lineno">   64</span>    <span class="keywordflow">for</span>(std::size_t i = 0; i &lt; W.size(); ++i)</div>
<div class="line"><a id="l00065" name="l00065"></a><span class="lineno">   65</span>    {</div>
<div class="line"><a id="l00066" name="l00066"></a><span class="lineno">   66</span>        <span class="comment">//dimension: L x L, where L is the number of basis</span></div>
<div class="line"><a id="l00067" name="l00067"></a><span class="lineno">   67</span>        <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> integrand = <a class="code hl_function" href="functional__matrix__product_8hpp.html#aeb98bde348f8f5eb62e272fb771ce869">fm_prod</a>(<a class="code hl_function" href="functional__matrix__product_8hpp.html#aeb98bde348f8f5eb62e272fb771ce869">fm_prod</a>(<a class="code hl_function" href="functional__matrix__product_8hpp.html#aeb98bde348f8f5eb62e272fb771ce869">fm_prod</a>(<a class="code hl_function" href="functional__matrix__product_8hpp.html#aeb98bde348f8f5eb62e272fb771ce869">fm_prod</a>(base_t,X_t),W[i],m_number_threads),X,m_number_threads),base);</div>
<div class="line"><a id="l00068" name="l00068"></a><span class="lineno">   68</span> </div>
<div class="line"><a id="l00069" name="l00069"></a><span class="lineno">   69</span>        <span class="comment">//performing integration and factorization</span></div>
<div class="line"><a id="l00070" name="l00070"></a><span class="lineno">   70</span>        penalty[i] = Eigen::PartialPivLU&lt; FDAGWR_TRAITS::Dense_Matrix &gt;( fm_integration(integrand) + _R_ );    </div>
<div class="line"><a id="l00071" name="l00071"></a><span class="lineno">   71</span>        <span class="comment">// penalty[i].solve(M) equivale a fare elemento penalty[i], che è una matrice inversa, times M</span></div>
<div class="line"><a id="l00072" name="l00072"></a><span class="lineno">   72</span>    }</div>
<div class="line"><a id="l00073" name="l00073"></a><span class="lineno">   73</span>    </div>
<div class="line"><a id="l00074" name="l00074"></a><span class="lineno">   74</span>    <span class="keywordflow">return</span> penalty;</div>
<div class="line"><a id="l00075" name="l00075"></a><span class="lineno">   75</span>}</div>
</div>
<div class="line"><a id="l00076" name="l00076"></a><span class="lineno">   76</span></div>
<div class="line"><a id="l00087" name="l00087"></a><span class="lineno">   87</span><span class="keyword">template</span>&lt; <span class="keyword">typename</span> INPUT, <span class="keyword">typename</span> OUTPUT &gt;</div>
<div class="line"><a id="l00088" name="l00088"></a><span class="lineno">   88</span>    <span class="keyword">requires</span> (std::integral&lt;INPUT&gt; || std::floating_point&lt;INPUT&gt;)  &amp;&amp;  (std::integral&lt;OUTPUT&gt; || std::floating_point&lt;OUTPUT&gt;)</div>
<div class="line"><a id="l00089" name="l00089"></a><span class="lineno">   89</span>std::vector&lt; Eigen::PartialPivLU&lt; FDAGWR_TRAITS::Dense_Matrix &gt; &gt;</div>
<div class="foldopen" id="foldopen00090" data-start="{" data-end="}">
<div class="line"><a id="l00090" name="l00090"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#a07376f2d9f52ca4aa2dc1eb0751c7ac4">   90</a></span><a class="code hl_function" href="classfwr__operator__computing.html#a634f00fe47b21671fb008f732eb7ec89">fwr_operator_computing&lt;INPUT,OUTPUT&gt;::compute_penalty</a>(<span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> &amp;X_crossed_t,</div>
<div class="line"><a id="l00091" name="l00091"></a><span class="lineno">   91</span>                                                      <span class="keyword">const</span> std::vector&lt; <a class="code hl_class" href="classfunctional__matrix__diagonal.html">functional_matrix_diagonal&lt;INPUT,OUTPUT&gt;</a> &gt; &amp;W,</div>
<div class="line"><a id="l00092" name="l00092"></a><span class="lineno">   92</span>                                                      <span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> &amp;X_crossed,</div>
<div class="line"><a id="l00093" name="l00093"></a><span class="lineno">   93</span>                                                      <span class="keyword">const</span> <a class="code hl_typedef" href="struct_f_d_a_g_w_r___t_r_a_i_t_s.html#a3c0ac6887d94bffa71939fba3c05fb98">FDAGWR_TRAITS::Sparse_Matrix</a> &amp;R)<span class="keyword"> </span></div>
<div class="line"><a id="l00094" name="l00094"></a><span class="lineno">   94</span><span class="keyword">const</span></div>
<div class="line"><a id="l00095" name="l00095"></a><span class="lineno">   95</span><span class="keyword"></span>{</div>
<div class="line"><a id="l00096" name="l00096"></a><span class="lineno">   96</span>    <span class="comment">//the vector contains factorization of the matrix</span></div>
<div class="line"><a id="l00097" name="l00097"></a><span class="lineno">   97</span>    std::vector&lt; Eigen::PartialPivLU&lt;FDAGWR_TRAITS::Dense_Matrix&gt; &gt; penalty;</div>
<div class="line"><a id="l00098" name="l00098"></a><span class="lineno">   98</span>    penalty.resize(W.size());</div>
<div class="line"><a id="l00099" name="l00099"></a><span class="lineno">   99</span> </div>
<div class="line"><a id="l00100" name="l00100"></a><span class="lineno">  100</span>    <a class="code hl_typedef" href="struct_f_d_a_g_w_r___t_r_a_i_t_s.html#a7480032013388cae40a69abf8d4ba297">FDAGWR_TRAITS::Dense_Matrix</a> _R_ = <a class="code hl_typedef" href="struct_f_d_a_g_w_r___t_r_a_i_t_s.html#a7480032013388cae40a69abf8d4ba297">FDAGWR_TRAITS::Dense_Matrix</a>(R);   <span class="comment">//necessary to compute the sum later</span></div>
<div class="line"><a id="l00101" name="l00101"></a><span class="lineno">  101</span> </div>
<div class="line"><a id="l00102" name="l00102"></a><span class="lineno">  102</span><span class="preprocessor">#ifdef _OPENMP</span></div>
<div class="line"><a id="l00103" name="l00103"></a><span class="lineno">  103</span><span class="preprocessor">#pragma omp parallel for shared(penalty,X_crossed_t,X_crossed,W,_R_,m_number_threads) num_threads(m_number_threads)</span></div>
<div class="line"><a id="l00104" name="l00104"></a><span class="lineno">  104</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l00105" name="l00105"></a><span class="lineno">  105</span>    <span class="keywordflow">for</span>(std::size_t i = 0; i &lt; W.size(); ++i)</div>
<div class="line"><a id="l00106" name="l00106"></a><span class="lineno">  106</span>    {</div>
<div class="line"><a id="l00107" name="l00107"></a><span class="lineno">  107</span>        <span class="comment">//dimension: L x L, where L is the number of basis</span></div>
<div class="line"><a id="l00108" name="l00108"></a><span class="lineno">  108</span>        <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> integrand = <a class="code hl_function" href="functional__matrix__product_8hpp.html#aeb98bde348f8f5eb62e272fb771ce869">fm_prod</a>(<a class="code hl_function" href="functional__matrix__product_8hpp.html#aeb98bde348f8f5eb62e272fb771ce869">fm_prod</a>(X_crossed_t,W[i],m_number_threads),X_crossed,m_number_threads);</div>
<div class="line"><a id="l00109" name="l00109"></a><span class="lineno">  109</span> </div>
<div class="line"><a id="l00110" name="l00110"></a><span class="lineno">  110</span>        <span class="comment">//performing integration and factorization</span></div>
<div class="foldopen" id="foldopen00111" data-start="{" data-end="}">
<div class="line"><a id="l00111" name="l00111"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#a634f00fe47b21671fb008f732eb7ec89">  111</a></span>        penalty[i] = Eigen::PartialPivLU&lt; FDAGWR_TRAITS::Dense_Matrix &gt;( fm_integration(integrand) + _R_ );    </div>
<div class="line"><a id="l00112" name="l00112"></a><span class="lineno">  112</span>        <span class="comment">// penalty[i].solve(M) equivale a fare elemento penalty[i], che è una matrice inversa, times M</span></div>
<div class="line"><a id="l00113" name="l00113"></a><span class="lineno">  113</span>    }</div>
<div class="line"><a id="l00114" name="l00114"></a><span class="lineno">  114</span>    </div>
<div class="line"><a id="l00115" name="l00115"></a><span class="lineno">  115</span>    <span class="keywordflow">return</span> penalty;</div>
<div class="line"><a id="l00116" name="l00116"></a><span class="lineno">  116</span>}</div>
<div class="line"><a id="l00117" name="l00117"></a><span class="lineno">  117</span></div>
<div class="line"><a id="l00128" name="l00128"></a><span class="lineno">  128</span><span class="keyword">template</span>&lt; <span class="keyword">typename</span> INPUT, <span class="keyword">typename</span> OUTPUT &gt;</div>
<div class="foldopen" id="foldopen00129" data-start="{" data-end="}">
<div class="line"><a id="l00129" name="l00129"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#a07376f2d9f52ca4aa2dc1eb0751c7ac4">  129</a></span>    <span class="keyword">requires</span> (std::integral&lt;INPUT&gt; || std::floating_point&lt;INPUT&gt;)  &amp;&amp;  (std::integral&lt;OUTPUT&gt; || std::floating_point&lt;OUTPUT&gt;)</div>
<div class="line"><a id="l00130" name="l00130"></a><span class="lineno">  130</span>Eigen::PartialPivLU&lt; FDAGWR_TRAITS::Dense_Matrix &gt;</div>
<div class="foldopen" id="foldopen00131" data-start="{" data-end="}">
<div class="line"><a id="l00131" name="l00131"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#af5dffd52e6171ec5215e6c88df7d037a">  131</a></span><a class="code hl_function" href="classfwr__operator__computing.html#a634f00fe47b21671fb008f732eb7ec89">fwr_operator_computing&lt;INPUT,OUTPUT&gt;::compute_penalty</a>(<span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> &amp;X_crossed_t,</div>
<div class="line"><a id="l00132" name="l00132"></a><span class="lineno">  132</span>                                                      <span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix__diagonal.html">functional_matrix_diagonal&lt;INPUT,OUTPUT&gt;</a> &amp;W,</div>
<div class="line"><a id="l00133" name="l00133"></a><span class="lineno">  133</span>                                                      <span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> &amp;X_crossed,</div>
<div class="line"><a id="l00134" name="l00134"></a><span class="lineno">  134</span>                                                      <span class="keyword">const</span> <a class="code hl_typedef" href="struct_f_d_a_g_w_r___t_r_a_i_t_s.html#a3c0ac6887d94bffa71939fba3c05fb98">FDAGWR_TRAITS::Sparse_Matrix</a> &amp;R)<span class="keyword"> </span></div>
<div class="line"><a id="l00135" name="l00135"></a><span class="lineno">  135</span><span class="keyword">const</span></div>
<div class="line"><a id="l00136" name="l00136"></a><span class="lineno">  136</span><span class="keyword"></span>{</div>
<div class="line"><a id="l00137" name="l00137"></a><span class="lineno">  137</span>    <a class="code hl_typedef" href="struct_f_d_a_g_w_r___t_r_a_i_t_s.html#a7480032013388cae40a69abf8d4ba297">FDAGWR_TRAITS::Dense_Matrix</a> _R_ = <a class="code hl_typedef" href="struct_f_d_a_g_w_r___t_r_a_i_t_s.html#a7480032013388cae40a69abf8d4ba297">FDAGWR_TRAITS::Dense_Matrix</a>(R);</div>
<div class="line"><a id="l00138" name="l00138"></a><span class="lineno">  138</span>    <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> integrand = <a class="code hl_function" href="functional__matrix__product_8hpp.html#aeb98bde348f8f5eb62e272fb771ce869">fm_prod</a>(<a class="code hl_function" href="functional__matrix__product_8hpp.html#aeb98bde348f8f5eb62e272fb771ce869">fm_prod</a>(X_crossed_t,W,m_number_threads),X_crossed,m_number_threads);</div>
<div class="line"><a id="l00139" name="l00139"></a><span class="lineno">  139</span> </div>
<div class="line"><a id="l00140" name="l00140"></a><span class="lineno">  140</span>    <span class="comment">//performing integration and factorization</span></div>
<div class="line"><a id="l00141" name="l00141"></a><span class="lineno">  141</span>    <span class="keywordflow">return</span> Eigen::PartialPivLU&lt; FDAGWR_TRAITS::Dense_Matrix &gt;( fm_integration(integrand) + _R_ ); </div>
<div class="line"><a id="l00142" name="l00142"></a><span class="lineno">  142</span>}</div>
</div>
<div class="line"><a id="l00143" name="l00143"></a><span class="lineno">  143</span></div>
<div class="foldopen" id="foldopen00145" data-start="{" data-end="}">
<div class="line"><a id="l00145" name="l00145"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#af5dffd52e6171ec5215e6c88df7d037a">  145</a></span><span class="comment">* @brief Compute [J + R]^(-1), where:</span></div>
<div class="line"><a id="l00146" name="l00146"></a><span class="lineno">  146</span><span class="comment">*        - J = int_a_b(base_t * X_t* W * X * base), where W is the functional weight. The integral of the matrix is element-wise</span></div>
<div class="line"><a id="l00147" name="l00147"></a><span class="lineno">  147</span><span class="comment">*        - R the penalization matrix, diagonal block-matrix, such that each block contains the inner product within a given derivative of basis systems, one block for each basis system</span></div>
<div class="line"><a id="l00148" name="l00148"></a><span class="lineno">  148</span><span class="comment">* @param base_t containing basis systems, one system for each row, one basis for each column, transpost</span></div>
<div class="line"><a id="l00149" name="l00149"></a><span class="lineno">  149</span><span class="comment">* @param X_t functional covariates, transpost</span></div>
<div class="line"><a id="l00150" name="l00150"></a><span class="lineno">  150</span><span class="comment">* @param W functional diagonal matrix, containing functional weights</span></div>
<div class="line"><a id="l00151" name="l00151"></a><span class="lineno">  151</span><span class="comment">* @param X functioal covaraites</span></div>
<div class="line"><a id="l00152" name="l00152"></a><span class="lineno">  152</span><span class="comment">* @param base containing basis systems, one system for each row, one basis for each column</span></div>
<div class="line"><a id="l00153" name="l00153"></a><span class="lineno">  153</span><span class="comment">* @param R penalization matrix</span></div>
<div class="line"><a id="l00154" name="l00154"></a><span class="lineno">  154</span><span class="comment">* @return partial PivLU of J + R</span></div>
<div class="line"><a id="l00155" name="l00155"></a><span class="lineno">  155</span><span class="comment">* @note is used when having only stationary covariates</span></div>
<div class="line"><a id="l00156" name="l00156"></a><span class="lineno">  156</span><span class="comment">*/</span></div>
<div class="line"><a id="l00157" name="l00157"></a><span class="lineno">  157</span><span class="keyword">template</span>&lt; <span class="keyword">typename</span> INPUT, <span class="keyword">typename</span> OUTPUT &gt;</div>
<div class="line"><a id="l00158" name="l00158"></a><span class="lineno">  158</span>    <span class="keyword">requires</span> (std::integral&lt;INPUT&gt; || std::floating_point&lt;INPUT&gt;)  &amp;&amp;  (std::integral&lt;OUTPUT&gt; || std::floating_point&lt;OUTPUT&gt;)</div>
<div class="line"><a id="l00159" name="l00159"></a><span class="lineno">  159</span>Eigen::PartialPivLU&lt; FDAGWR_TRAITS::Dense_Matrix &gt;</div>
<div class="foldopen" id="foldopen00160" data-start="{" data-end="}">
<div class="line"><a id="l00160" name="l00160"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#a047bdd074eb94352ed4a68d1a8e34420">  160</a></span><a class="code hl_function" href="classfwr__operator__computing.html#a634f00fe47b21671fb008f732eb7ec89">fwr_operator_computing&lt;INPUT,OUTPUT&gt;::compute_penalty</a>(<span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix__sparse.html">functional_matrix_sparse&lt;INPUT,OUTPUT&gt;</a> &amp;base_t,</div>
<div class="line"><a id="l00161" name="l00161"></a><span class="lineno">  161</span>                                                      <span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> &amp;X_t,</div>
<div class="line"><a id="l00162" name="l00162"></a><span class="lineno">  162</span>                                                      <span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix__diagonal.html">functional_matrix_diagonal&lt;INPUT,OUTPUT&gt;</a> &amp;W,</div>
<div class="line"><a id="l00163" name="l00163"></a><span class="lineno">  163</span>                                                      <span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> &amp;X,</div>
<div class="foldopen" id="foldopen00164" data-start="{" data-end="}">
<div class="line"><a id="l00164" name="l00164"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#a047bdd074eb94352ed4a68d1a8e34420">  164</a></span>                                                      <span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix__sparse.html">functional_matrix_sparse&lt;INPUT,OUTPUT&gt;</a> &amp;base,</div>
<div class="line"><a id="l00165" name="l00165"></a><span class="lineno">  165</span>                                                      <span class="keyword">const</span> <a class="code hl_typedef" href="struct_f_d_a_g_w_r___t_r_a_i_t_s.html#a3c0ac6887d94bffa71939fba3c05fb98">FDAGWR_TRAITS::Sparse_Matrix</a> &amp;R)<span class="keyword"></span></div>
<div class="line"><a id="l00166" name="l00166"></a><span class="lineno">  166</span><span class="keyword">const</span></div>
<div class="line"><a id="l00167" name="l00167"></a><span class="lineno">  167</span><span class="keyword"></span>{   </div>
<div class="line"><a id="l00168" name="l00168"></a><span class="lineno">  168</span>    <a class="code hl_typedef" href="struct_f_d_a_g_w_r___t_r_a_i_t_s.html#a7480032013388cae40a69abf8d4ba297">FDAGWR_TRAITS::Dense_Matrix</a> _R_ = <a class="code hl_typedef" href="struct_f_d_a_g_w_r___t_r_a_i_t_s.html#a7480032013388cae40a69abf8d4ba297">FDAGWR_TRAITS::Dense_Matrix</a>(R);</div>
<div class="line"><a id="l00169" name="l00169"></a><span class="lineno">  169</span>    <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> integrand = <a class="code hl_function" href="functional__matrix__product_8hpp.html#aeb98bde348f8f5eb62e272fb771ce869">fm_prod</a>(<a class="code hl_function" href="functional__matrix__product_8hpp.html#aeb98bde348f8f5eb62e272fb771ce869">fm_prod</a>(<a class="code hl_function" href="functional__matrix__product_8hpp.html#aeb98bde348f8f5eb62e272fb771ce869">fm_prod</a>(<a class="code hl_function" href="functional__matrix__product_8hpp.html#aeb98bde348f8f5eb62e272fb771ce869">fm_prod</a>(base_t,X_t),W,m_number_threads),X,m_number_threads),base);</div>
<div class="line"><a id="l00170" name="l00170"></a><span class="lineno">  170</span> </div>
<div class="line"><a id="l00171" name="l00171"></a><span class="lineno">  171</span>    <span class="comment">//performing integration and factorization</span></div>
<div class="line"><a id="l00172" name="l00172"></a><span class="lineno">  172</span>    <span class="keywordflow">return</span> Eigen::PartialPivLU&lt; FDAGWR_TRAITS::Dense_Matrix &gt;( this-&gt;fm_integration(integrand) + _R_ ); </div>
<div class="line"><a id="l00173" name="l00173"></a><span class="lineno">  173</span>}</div>
</div>
</div>
<div class="line"><a id="l00174" name="l00174"></a><span class="lineno">  174</span></div>
<div class="foldopen" id="foldopen00183" data-start="{" data-end="}">
<div class="line"><a id="l00183" name="l00183"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#a20202c6ca2e008c6f37014232c9d8506">  183</a></span><span class="comment">* @param penalty vector of partial PivLU decomposition, containing the penalties [J_i + R]^(-1) as computed by the functions above</span></div>
<div class="line"><a id="l00184" name="l00184"></a><span class="lineno">  184</span><span class="comment">* @return a matrix containing the element-wise integration</span></div>
<div class="line"><a id="l00185" name="l00185"></a><span class="lineno">  185</span><span class="comment">*/</span></div>
<div class="line"><a id="l00186" name="l00186"></a><span class="lineno">  186</span><span class="keyword">template</span>&lt; <span class="keyword">typename</span> INPUT, <span class="keyword">typename</span> OUTPUT &gt;</div>
<div class="line"><a id="l00187" name="l00187"></a><span class="lineno">  187</span>    <span class="keyword">requires</span> (std::integral&lt;INPUT&gt; || std::floating_point&lt;INPUT&gt;)  &amp;&amp;  (std::integral&lt;OUTPUT&gt; || std::floating_point&lt;OUTPUT&gt;)</div>
<div class="line"><a id="l00188" name="l00188"></a><span class="lineno">  188</span>std::vector&lt; FDAGWR_TRAITS::Dense_Matrix &gt;</div>
<div class="foldopen" id="foldopen00189" data-start="{" data-end="}">
<div class="line"><a id="l00189" name="l00189"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#a20202c6ca2e008c6f37014232c9d8506">  189</a></span><a class="code hl_function" href="classfwr__operator__computing.html#a20202c6ca2e008c6f37014232c9d8506">fwr_operator_computing&lt;INPUT,OUTPUT&gt;::compute_operator</a>(<span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix__sparse.html">functional_matrix_sparse&lt;INPUT,OUTPUT&gt;</a> &amp;base_lhs,</div>
<div class="line"><a id="l00190" name="l00190"></a><span class="lineno">  190</span>                                                       <span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> &amp;X_lhs,</div>
<div class="line"><a id="l00191" name="l00191"></a><span class="lineno">  191</span>                                                       <span class="keyword">const</span> std::vector&lt; <a class="code hl_class" href="classfunctional__matrix__diagonal.html">functional_matrix_diagonal&lt;INPUT,OUTPUT&gt;</a> &gt; &amp;W,</div>
<div class="line"><a id="l00192" name="l00192"></a><span class="lineno">  192</span>                                                       <span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> &amp;X_rhs,</div>
<div class="line"><a id="l00193" name="l00193"></a><span class="lineno">  193</span>                                                       <span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix__sparse.html">functional_matrix_sparse&lt;INPUT,OUTPUT&gt;</a> &amp;base_rhs,</div>
<div class="line"><a id="l00194" name="l00194"></a><span class="lineno">  194</span>                                                       <span class="keyword">const</span> std::vector&lt; Eigen::PartialPivLU&lt; FDAGWR_TRAITS::Dense_Matrix &gt; &gt; &amp;penalty)<span class="keyword"> </span></div>
<div class="line"><a id="l00195" name="l00195"></a><span class="lineno">  195</span><span class="keyword">const</span></div>
<div class="line"><a id="l00196" name="l00196"></a><span class="lineno">  196</span><span class="keyword"></span>{</div>
<div class="line"><a id="l00197" name="l00197"></a><span class="lineno">  197</span>    <span class="comment">//the vector contains factorization of the matrix</span></div>
<div class="line"><a id="l00198" name="l00198"></a><span class="lineno">  198</span>    std::vector&lt; FDAGWR_TRAITS::Dense_Matrix &gt; _operator_;</div>
<div class="line"><a id="l00199" name="l00199"></a><span class="lineno">  199</span>    _operator_.resize(W.size());</div>
<div class="line"><a id="l00200" name="l00200"></a><span class="lineno">  200</span> </div>
<div class="foldopen" id="foldopen00201" data-start="{" data-end="}">
<div class="line"><a id="l00201" name="l00201"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#a8f907af0a410a506ab9ab00d5874fe2f">  201</a></span><span class="preprocessor">#ifdef _OPENMP</span></div>
<div class="line"><a id="l00202" name="l00202"></a><span class="lineno">  202</span><span class="preprocessor">#pragma omp parallel for shared(_operator_,penalty,base_lhs,X_lhs,X_rhs,base_rhs,W,m_number_threads) num_threads(m_number_threads)</span></div>
<div class="line"><a id="l00203" name="l00203"></a><span class="lineno">  203</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l00204" name="l00204"></a><span class="lineno">  204</span>    <span class="keywordflow">for</span>(std::size_t i = 0; i &lt; W.size(); ++i)</div>
<div class="line"><a id="l00205" name="l00205"></a><span class="lineno">  205</span>    {       </div>
<div class="line"><a id="l00206" name="l00206"></a><span class="lineno">  206</span>        <span class="comment">//dimension: L_lhs x L_rhs, where L is the number of basis (the left basis is transpost)</span></div>
<div class="line"><a id="l00207" name="l00207"></a><span class="lineno">  207</span>        <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> integrand = <a class="code hl_function" href="functional__matrix__product_8hpp.html#aeb98bde348f8f5eb62e272fb771ce869">fm_prod</a>(<a class="code hl_function" href="functional__matrix__product_8hpp.html#aeb98bde348f8f5eb62e272fb771ce869">fm_prod</a>(<a class="code hl_function" href="functional__matrix__product_8hpp.html#aeb98bde348f8f5eb62e272fb771ce869">fm_prod</a>(<a class="code hl_function" href="functional__matrix__product_8hpp.html#aeb98bde348f8f5eb62e272fb771ce869">fm_prod</a>(base_lhs,X_lhs),W[i],m_number_threads),X_rhs,m_number_threads),base_rhs);</div>
<div class="line"><a id="l00208" name="l00208"></a><span class="lineno">  208</span> </div>
<div class="line"><a id="l00209" name="l00209"></a><span class="lineno">  209</span>        <span class="comment">//performing integration and multiplication with the penalty (inverse factorized)</span></div>
<div class="line"><a id="l00210" name="l00210"></a><span class="lineno">  210</span>        _operator_[i] = penalty[i].solve( fm_integration(integrand) ); </div>
<div class="line"><a id="l00211" name="l00211"></a><span class="lineno">  211</span>    }</div>
<div class="line"><a id="l00212" name="l00212"></a><span class="lineno">  212</span> </div>
<div class="line"><a id="l00213" name="l00213"></a><span class="lineno">  213</span>    <span class="keywordflow">return</span> _operator_;</div>
<div class="line"><a id="l00214" name="l00214"></a><span class="lineno">  214</span>}</div>
<div class="line"><a id="l00215" name="l00215"></a><span class="lineno">  215</span></div>
<div class="foldopen" id="foldopen00218" data-start="{" data-end="}">
<div class="line"><a id="l00218" name="l00218"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#a1969dab480695ed4b5127a5a7ed71838">  218</a></span><span class="comment">*        [J_i + R]^(-1) * int_a_b(base_lhs * X_lhs * W_i * base_rhs), where W_i is the functional weight of the i-th units. The integral of the matrix is element-wise</span></div>
<div class="line"><a id="l00219" name="l00219"></a><span class="lineno">  219</span><span class="comment">* @param base_lhs containing basis systems, one system for each row, one basis for each column</span></div>
<div class="line"><a id="l00220" name="l00220"></a><span class="lineno">  220</span><span class="comment">* @param X_lhs functional data matrix</span></div>
<div class="line"><a id="l00221" name="l00221"></a><span class="lineno">  221</span><span class="comment">* @param W vector of functional diagonal matrices, containing, for each unit, functional weights</span></div>
<div class="line"><a id="l00222" name="l00222"></a><span class="lineno">  222</span><span class="comment">* @param base_rhs containing basis systems, one system for each row, one basis for each column</span></div>
<div class="line"><a id="l00223" name="l00223"></a><span class="lineno">  223</span><span class="comment">* @param penalty vector of partial PivLU decomposition, containing the penalties [J_i + R]^(-1) as computed by the functions above</span></div>
<div class="line"><a id="l00224" name="l00224"></a><span class="lineno">  224</span><span class="comment">* @return a matrix containing the element-wise integration</span></div>
<div class="line"><a id="l00225" name="l00225"></a><span class="lineno">  225</span><span class="comment">*/</span></div>
<div class="line"><a id="l00226" name="l00226"></a><span class="lineno">  226</span><span class="keyword">template</span>&lt; <span class="keyword">typename</span> INPUT, <span class="keyword">typename</span> OUTPUT &gt;</div>
<div class="line"><a id="l00227" name="l00227"></a><span class="lineno">  227</span>    <span class="keyword">requires</span> (std::integral&lt;INPUT&gt; || std::floating_point&lt;INPUT&gt;)  &amp;&amp;  (std::integral&lt;OUTPUT&gt; || std::floating_point&lt;OUTPUT&gt;)</div>
<div class="line"><a id="l00228" name="l00228"></a><span class="lineno">  228</span>std::vector&lt; FDAGWR_TRAITS::Dense_Matrix &gt;</div>
<div class="foldopen" id="foldopen00229" data-start="{" data-end="}">
<div class="line"><a id="l00229" name="l00229"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#a8f907af0a410a506ab9ab00d5874fe2f">  229</a></span><a class="code hl_function" href="classfwr__operator__computing.html#a20202c6ca2e008c6f37014232c9d8506">fwr_operator_computing&lt;INPUT,OUTPUT&gt;::compute_operator</a>(<span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix__sparse.html">functional_matrix_sparse&lt;INPUT,OUTPUT&gt;</a> &amp;base_lhs,</div>
<div class="line"><a id="l00230" name="l00230"></a><span class="lineno">  230</span>                                                       <span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> &amp;X_lhs,</div>
<div class="line"><a id="l00231" name="l00231"></a><span class="lineno">  231</span>                                                       <span class="keyword">const</span> std::vector&lt; <a class="code hl_class" href="classfunctional__matrix__diagonal.html">functional_matrix_diagonal&lt;INPUT,OUTPUT&gt;</a> &gt; &amp;W,</div>
<div class="line"><a id="l00232" name="l00232"></a><span class="lineno">  232</span>                                                       <span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix__sparse.html">functional_matrix_sparse&lt;INPUT,OUTPUT&gt;</a> &amp;base_rhs,</div>
<div class="line"><a id="l00233" name="l00233"></a><span class="lineno">  233</span>                                                       <span class="keyword">const</span> std::vector&lt; Eigen::PartialPivLU&lt; FDAGWR_TRAITS::Dense_Matrix &gt; &gt; &amp;penalty)<span class="keyword"> </span></div>
<div class="foldopen" id="foldopen00234" data-start="{" data-end="}">
<div class="line"><a id="l00234" name="l00234"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#ae991174a286a8e2df8c4e551c111d917">  234</a></span><span class="keyword">const</span></div>
<div class="line"><a id="l00235" name="l00235"></a><span class="lineno">  235</span><span class="keyword"></span>{</div>
<div class="line"><a id="l00236" name="l00236"></a><span class="lineno">  236</span>    <span class="comment">//the vector contains factorization of the matrix</span></div>
<div class="line"><a id="l00237" name="l00237"></a><span class="lineno">  237</span>    std::vector&lt; FDAGWR_TRAITS::Dense_Matrix &gt; _operator_;</div>
<div class="line"><a id="l00238" name="l00238"></a><span class="lineno">  238</span>    _operator_.resize(W.size());</div>
<div class="line"><a id="l00239" name="l00239"></a><span class="lineno">  239</span> </div>
<div class="line"><a id="l00240" name="l00240"></a><span class="lineno">  240</span><span class="preprocessor">#ifdef _OPENMP</span></div>
<div class="line"><a id="l00241" name="l00241"></a><span class="lineno">  241</span><span class="preprocessor">#pragma omp parallel for shared(_operator_,penalty,base_lhs,X_lhs,base_rhs,W,m_number_threads) num_threads(m_number_threads)</span></div>
<div class="line"><a id="l00242" name="l00242"></a><span class="lineno">  242</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l00243" name="l00243"></a><span class="lineno">  243</span>    <span class="keywordflow">for</span>(std::size_t i = 0; i &lt; W.size(); ++i)</div>
<div class="line"><a id="l00244" name="l00244"></a><span class="lineno">  244</span>    {       </div>
<div class="line"><a id="l00245" name="l00245"></a><span class="lineno">  245</span>        <span class="comment">//dimension: L_lhs x L_rhs, where L is the number of basis (the left basis is transpost)</span></div>
<div class="line"><a id="l00246" name="l00246"></a><span class="lineno">  246</span>        <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> integrand = <a class="code hl_function" href="functional__matrix__product_8hpp.html#aeb98bde348f8f5eb62e272fb771ce869">fm_prod</a>(<a class="code hl_function" href="functional__matrix__product_8hpp.html#aeb98bde348f8f5eb62e272fb771ce869">fm_prod</a>(<a class="code hl_function" href="functional__matrix__product_8hpp.html#aeb98bde348f8f5eb62e272fb771ce869">fm_prod</a>(base_lhs,X_lhs),W[i],m_number_threads),base_rhs);</div>
<div class="line"><a id="l00247" name="l00247"></a><span class="lineno">  247</span> </div>
<div class="line"><a id="l00248" name="l00248"></a><span class="lineno">  248</span>        <span class="comment">//performing integration and multiplication with the penalty (inverse factorized)</span></div>
<div class="foldopen" id="foldopen00249" data-start="{" data-end="}">
<div class="line"><a id="l00249" name="l00249"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#a89a4b981848bde4c0801fb1accc74496">  249</a></span>        _operator_[i] = penalty[i].solve( fm_integration(integrand) ); </div>
<div class="line"><a id="l00250" name="l00250"></a><span class="lineno">  250</span>    }</div>
<div class="line"><a id="l00251" name="l00251"></a><span class="lineno">  251</span> </div>
<div class="line"><a id="l00252" name="l00252"></a><span class="lineno">  252</span>    <span class="keywordflow">return</span> _operator_;</div>
<div class="line"><a id="l00253" name="l00253"></a><span class="lineno">  253</span>}</div>
<div class="line"><a id="l00254" name="l00254"></a><span class="lineno">  254</span></div>
<div class="foldopen" id="foldopen00265" data-start="{" data-end="}">
<div class="line"><a id="l00265" name="l00265"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#a347e8cf6b149f3edd93be4370c376e6d">  265</a></span><span class="keyword">template</span>&lt; <span class="keyword">typename</span> INPUT, <span class="keyword">typename</span> OUTPUT &gt;</div>
<div class="line"><a id="l00266" name="l00266"></a><span class="lineno">  266</span>    <span class="keyword">requires</span> (std::integral&lt;INPUT&gt; || std::floating_point&lt;INPUT&gt;)  &amp;&amp;  (std::integral&lt;OUTPUT&gt; || std::floating_point&lt;OUTPUT&gt;)</div>
<div class="line"><a id="l00267" name="l00267"></a><span class="lineno">  267</span>std::vector&lt; FDAGWR_TRAITS::Dense_Matrix &gt;</div>
<div class="foldopen" id="foldopen00268" data-start="{" data-end="}">
<div class="line"><a id="l00268" name="l00268"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#a1969dab480695ed4b5127a5a7ed71838">  268</a></span><a class="code hl_function" href="classfwr__operator__computing.html#a20202c6ca2e008c6f37014232c9d8506">fwr_operator_computing&lt;INPUT,OUTPUT&gt;::compute_operator</a>(<span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> &amp;X_lhs,</div>
<div class="line"><a id="l00269" name="l00269"></a><span class="lineno">  269</span>                                                       <span class="keyword">const</span> std::vector&lt; <a class="code hl_class" href="classfunctional__matrix__diagonal.html">functional_matrix_diagonal&lt;INPUT,OUTPUT&gt;</a> &gt; &amp;W,</div>
<div class="line"><a id="l00270" name="l00270"></a><span class="lineno">  270</span>                                                       <span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> &amp;X_rhs,</div>
<div class="line"><a id="l00271" name="l00271"></a><span class="lineno">  271</span>                                                       <span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix__sparse.html">functional_matrix_sparse&lt;INPUT,OUTPUT&gt;</a> &amp;base_rhs,</div>
<div class="line"><a id="l00272" name="l00272"></a><span class="lineno">  272</span>                                                       <span class="keyword">const</span> std::vector&lt; Eigen::PartialPivLU&lt; FDAGWR_TRAITS::Dense_Matrix &gt; &gt; &amp;penalty)<span class="keyword"> </span></div>
<div class="line"><a id="l00273" name="l00273"></a><span class="lineno">  273</span><span class="keyword">const</span></div>
<div class="line"><a id="l00274" name="l00274"></a><span class="lineno">  274</span><span class="keyword"></span>{</div>
<div class="line"><a id="l00275" name="l00275"></a><span class="lineno">  275</span>    <span class="comment">//the vector contains factorization of the matrix</span></div>
<div class="line"><a id="l00276" name="l00276"></a><span class="lineno">  276</span>    std::vector&lt; FDAGWR_TRAITS::Dense_Matrix &gt; _operator_;</div>
<div class="line"><a id="l00277" name="l00277"></a><span class="lineno">  277</span>    _operator_.resize(W.size());</div>
<div class="line"><a id="l00278" name="l00278"></a><span class="lineno">  278</span> </div>
<div class="line"><a id="l00279" name="l00279"></a><span class="lineno">  279</span><span class="preprocessor">#ifdef _OPENMP</span></div>
<div class="foldopen" id="foldopen00280" data-start="{" data-end="}">
<div class="line"><a id="l00280" name="l00280"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#a244d1696c290c92e368999c4ac7c50c1">  280</a></span><span class="preprocessor">#pragma omp parallel for shared(_operator_,penalty,X_lhs,X_rhs,base_rhs,W,m_number_threads) num_threads(m_number_threads)</span></div>
<div class="line"><a id="l00281" name="l00281"></a><span class="lineno">  281</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l00282" name="l00282"></a><span class="lineno">  282</span>    <span class="keywordflow">for</span>(std::size_t i = 0; i &lt; W.size(); ++i)</div>
<div class="line"><a id="l00283" name="l00283"></a><span class="lineno">  283</span>    {       </div>
<div class="line"><a id="l00284" name="l00284"></a><span class="lineno">  284</span>        <span class="comment">//dimension: L_lhs x L_rhs, where L is the number of basis (the left basis is transpost)</span></div>
<div class="line"><a id="l00285" name="l00285"></a><span class="lineno">  285</span>        <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> integrand = <a class="code hl_function" href="functional__matrix__product_8hpp.html#aeb98bde348f8f5eb62e272fb771ce869">fm_prod</a>(<a class="code hl_function" href="functional__matrix__product_8hpp.html#aeb98bde348f8f5eb62e272fb771ce869">fm_prod</a>(<a class="code hl_function" href="functional__matrix__product_8hpp.html#aeb98bde348f8f5eb62e272fb771ce869">fm_prod</a>(X_lhs,W[i],m_number_threads),X_rhs,m_number_threads),base_rhs);</div>
<div class="line"><a id="l00286" name="l00286"></a><span class="lineno">  286</span> </div>
<div class="line"><a id="l00287" name="l00287"></a><span class="lineno">  287</span>        <span class="comment">//performing integration and multiplication with the penalty (inverse factorized)</span></div>
<div class="line"><a id="l00288" name="l00288"></a><span class="lineno">  288</span>        _operator_[i] = penalty[i].solve( fm_integration(integrand) ); </div>
<div class="line"><a id="l00289" name="l00289"></a><span class="lineno">  289</span>    }</div>
<div class="line"><a id="l00290" name="l00290"></a><span class="lineno">  290</span> </div>
<div class="line"><a id="l00291" name="l00291"></a><span class="lineno">  291</span>    <span class="keywordflow">return</span> _operator_;</div>
<div class="line"><a id="l00292" name="l00292"></a><span class="lineno">  292</span>}</div>
<div class="line"><a id="l00293" name="l00293"></a><span class="lineno">  293</span></div>
<div class="foldopen" id="foldopen00296" data-start="{" data-end="}">
<div class="line"><a id="l00296" name="l00296"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#a0639842962ed1aff6d1842d8ac4ad9b0">  296</a></span><span class="comment">*        [J_i + R]^(-1) * int_a_b(X_lhs * W_i * base_rhs), where W_i is the functional weight of the i-th units. The integral of the matrix is element-wise</span></div>
<div class="line"><a id="l00297" name="l00297"></a><span class="lineno">  297</span><span class="comment">* @param X_lhs functional data matrix</span></div>
<div class="line"><a id="l00298" name="l00298"></a><span class="lineno">  298</span><span class="comment">* @param W vector of functional diagonal matrices, containing, for each unit, functional weights</span></div>
<div class="line"><a id="l00299" name="l00299"></a><span class="lineno">  299</span><span class="comment">* @param base_rhs containing basis systems, one system for each row, one basis for each column</span></div>
<div class="line"><a id="l00300" name="l00300"></a><span class="lineno">  300</span><span class="comment">* @param penalty vector of partial PivLU decomposition, containing the penalties [J_i + R]^(-1) as computed by the functions above</span></div>
<div class="line"><a id="l00301" name="l00301"></a><span class="lineno">  301</span><span class="comment">* @return a matrix containing the element-wise integration</span></div>
<div class="line"><a id="l00302" name="l00302"></a><span class="lineno">  302</span><span class="comment">*/</span></div>
<div class="line"><a id="l00303" name="l00303"></a><span class="lineno">  303</span><span class="keyword">template</span>&lt; <span class="keyword">typename</span> INPUT, <span class="keyword">typename</span> OUTPUT &gt;</div>
<div class="line"><a id="l00304" name="l00304"></a><span class="lineno">  304</span>    <span class="keyword">requires</span> (std::integral&lt;INPUT&gt; || std::floating_point&lt;INPUT&gt;)  &amp;&amp;  (std::integral&lt;OUTPUT&gt; || std::floating_point&lt;OUTPUT&gt;)</div>
<div class="line"><a id="l00305" name="l00305"></a><span class="lineno">  305</span>std::vector&lt; FDAGWR_TRAITS::Dense_Matrix &gt;</div>
<div class="foldopen" id="foldopen00306" data-start="{" data-end="}">
<div class="line"><a id="l00306" name="l00306"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#ae991174a286a8e2df8c4e551c111d917">  306</a></span><a class="code hl_function" href="classfwr__operator__computing.html#a20202c6ca2e008c6f37014232c9d8506">fwr_operator_computing&lt;INPUT,OUTPUT&gt;::compute_operator</a>(<span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> &amp;X_lhs,</div>
<div class="line"><a id="l00307" name="l00307"></a><span class="lineno">  307</span>                                                       <span class="keyword">const</span> std::vector&lt; <a class="code hl_class" href="classfunctional__matrix__diagonal.html">functional_matrix_diagonal&lt;INPUT,OUTPUT&gt;</a> &gt; &amp;W,</div>
<div class="line"><a id="l00308" name="l00308"></a><span class="lineno">  308</span>                                                       <span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix__sparse.html">functional_matrix_sparse&lt;INPUT,OUTPUT&gt;</a> &amp;base_rhs,</div>
<div class="line"><a id="l00309" name="l00309"></a><span class="lineno">  309</span>                                                       <span class="keyword">const</span> std::vector&lt; Eigen::PartialPivLU&lt; FDAGWR_TRAITS::Dense_Matrix &gt; &gt; &amp;penalty)<span class="keyword"> </span></div>
<div class="line"><a id="l00310" name="l00310"></a><span class="lineno">  310</span><span class="keyword">const</span></div>
<div class="foldopen" id="foldopen00311" data-start="{" data-end="}">
<div class="line"><a id="l00311" name="l00311"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#a2b15bc86a2d8daaef9934398adcd7116">  311</a></span><span class="keyword"></span>{</div>
<div class="line"><a id="l00312" name="l00312"></a><span class="lineno">  312</span>    <span class="comment">//the vector contains factorization of the matrix</span></div>
<div class="line"><a id="l00313" name="l00313"></a><span class="lineno">  313</span>    std::vector&lt; FDAGWR_TRAITS::Dense_Matrix &gt; _operator_;</div>
<div class="line"><a id="l00314" name="l00314"></a><span class="lineno">  314</span>    _operator_.resize(W.size());</div>
<div class="line"><a id="l00315" name="l00315"></a><span class="lineno">  315</span> </div>
<div class="line"><a id="l00316" name="l00316"></a><span class="lineno">  316</span><span class="preprocessor">#ifdef _OPENMP</span></div>
<div class="line"><a id="l00317" name="l00317"></a><span class="lineno">  317</span><span class="preprocessor">#pragma omp parallel for shared(_operator_,penalty,X_lhs,base_rhs,W,m_number_threads) num_threads(m_number_threads)</span></div>
<div class="line"><a id="l00318" name="l00318"></a><span class="lineno">  318</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l00319" name="l00319"></a><span class="lineno">  319</span>    <span class="keywordflow">for</span>(std::size_t i = 0; i &lt; W.size(); ++i)</div>
<div class="line"><a id="l00320" name="l00320"></a><span class="lineno">  320</span>    {       </div>
<div class="line"><a id="l00321" name="l00321"></a><span class="lineno">  321</span>        <span class="comment">//dimension: L_lhs x L_rhs, where L is the number of basis (the left basis is transpost)</span></div>
<div class="line"><a id="l00322" name="l00322"></a><span class="lineno">  322</span>        <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> integrand = <a class="code hl_function" href="functional__matrix__product_8hpp.html#aeb98bde348f8f5eb62e272fb771ce869">fm_prod</a>(<a class="code hl_function" href="functional__matrix__product_8hpp.html#aeb98bde348f8f5eb62e272fb771ce869">fm_prod</a>(X_lhs,W[i],m_number_threads),base_rhs);</div>
<div class="foldopen" id="foldopen00323" data-start="{" data-end="}">
<div class="line"><a id="l00323" name="l00323"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#a0f9fba8f012107fd443b687ba90b9886">  323</a></span> </div>
<div class="line"><a id="l00324" name="l00324"></a><span class="lineno">  324</span>        <span class="comment">//performing integration and multiplication with the penalty (inverse factorized)</span></div>
<div class="line"><a id="l00325" name="l00325"></a><span class="lineno">  325</span>        _operator_[i] = penalty[i].solve( fm_integration(integrand) ); </div>
<div class="line"><a id="l00326" name="l00326"></a><span class="lineno">  326</span>    }</div>
<div class="line"><a id="l00327" name="l00327"></a><span class="lineno">  327</span> </div>
<div class="line"><a id="l00328" name="l00328"></a><span class="lineno">  328</span>    <span class="keywordflow">return</span> _operator_;</div>
<div class="line"><a id="l00329" name="l00329"></a><span class="lineno">  329</span>}</div>
<div class="line"><a id="l00330" name="l00330"></a><span class="lineno">  330</span></div>
<div class="foldopen" id="foldopen00336" data-start="{" data-end="}">
<div class="line"><a id="l00336" name="l00336"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#a5a6ab857c0278a75a5b97b9496603de0">  336</a></span><span class="comment">* @param X_rhs functional data matrix</span></div>
<div class="line"><a id="l00337" name="l00337"></a><span class="lineno">  337</span><span class="comment">* @param penalty vector of partial PivLU decomposition, containing the penalties [J_i + R]^(-1) as computed by the functions above</span></div>
<div class="line"><a id="l00338" name="l00338"></a><span class="lineno">  338</span><span class="comment">* @return a matrix containing the element-wise integration</span></div>
<div class="line"><a id="l00339" name="l00339"></a><span class="lineno">  339</span><span class="comment">*/</span></div>
<div class="line"><a id="l00340" name="l00340"></a><span class="lineno">  340</span><span class="keyword">template</span>&lt; <span class="keyword">typename</span> INPUT, <span class="keyword">typename</span> OUTPUT &gt;</div>
<div class="line"><a id="l00341" name="l00341"></a><span class="lineno">  341</span>    <span class="keyword">requires</span> (std::integral&lt;INPUT&gt; || std::floating_point&lt;INPUT&gt;)  &amp;&amp;  (std::integral&lt;OUTPUT&gt; || std::floating_point&lt;OUTPUT&gt;)</div>
<div class="line"><a id="l00342" name="l00342"></a><span class="lineno">  342</span>std::vector&lt; FDAGWR_TRAITS::Dense_Matrix &gt;</div>
<div class="foldopen" id="foldopen00343" data-start="{" data-end="}">
<div class="line"><a id="l00343" name="l00343"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#a89a4b981848bde4c0801fb1accc74496">  343</a></span><a class="code hl_function" href="classfwr__operator__computing.html#a20202c6ca2e008c6f37014232c9d8506">fwr_operator_computing&lt;INPUT,OUTPUT&gt;::compute_operator</a>(<span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> &amp;X_lhs,</div>
<div class="line"><a id="l00344" name="l00344"></a><span class="lineno">  344</span>                                                       <span class="keyword">const</span> std::vector&lt; <a class="code hl_class" href="classfunctional__matrix__diagonal.html">functional_matrix_diagonal&lt;INPUT,OUTPUT&gt;</a> &gt; &amp;W,</div>
<div class="line"><a id="l00345" name="l00345"></a><span class="lineno">  345</span>                                                       <span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> &amp;X_rhs,</div>
<div class="line"><a id="l00346" name="l00346"></a><span class="lineno">  346</span>                                                       <span class="keyword">const</span> std::vector&lt; Eigen::PartialPivLU&lt; FDAGWR_TRAITS::Dense_Matrix &gt; &gt; &amp;penalty)<span class="keyword"> </span></div>
<div class="line"><a id="l00347" name="l00347"></a><span class="lineno">  347</span><span class="keyword">const</span></div>
<div class="foldopen" id="foldopen00348" data-start="{" data-end="}">
<div class="line"><a id="l00348" name="l00348"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#ab63b635a1edc829c2652e54a66f446b2">  348</a></span><span class="keyword"></span>{</div>
<div class="line"><a id="l00349" name="l00349"></a><span class="lineno">  349</span>    <span class="comment">//the vector contains factorization of the matrix</span></div>
<div class="line"><a id="l00350" name="l00350"></a><span class="lineno">  350</span>    std::vector&lt; FDAGWR_TRAITS::Dense_Matrix &gt; _operator_;</div>
<div class="line"><a id="l00351" name="l00351"></a><span class="lineno">  351</span>    _operator_.resize(W.size());</div>
<div class="line"><a id="l00352" name="l00352"></a><span class="lineno">  352</span> </div>
<div class="line"><a id="l00353" name="l00353"></a><span class="lineno">  353</span><span class="preprocessor">#ifdef _OPENMP</span></div>
<div class="line"><a id="l00354" name="l00354"></a><span class="lineno">  354</span><span class="preprocessor">#pragma omp parallel for shared(_operator_,penalty,X_lhs,X_rhs,W,m_number_threads) num_threads(m_number_threads)</span></div>
<div class="line"><a id="l00355" name="l00355"></a><span class="lineno">  355</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l00356" name="l00356"></a><span class="lineno">  356</span>    <span class="keywordflow">for</span>(std::size_t i = 0; i &lt; W.size(); ++i)</div>
<div class="line"><a id="l00357" name="l00357"></a><span class="lineno">  357</span>    {       </div>
<div class="line"><a id="l00358" name="l00358"></a><span class="lineno">  358</span>        <span class="comment">//dimension: L_lhs x L_rhs, where L is the number of basis (the left basis is transpost)</span></div>
<div class="foldopen" id="foldopen00359" data-start="{" data-end="}">
<div class="line"><a id="l00359" name="l00359"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#ab3120096261e2ba6c7536b9006dc3419">  359</a></span>        <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> integrand = <a class="code hl_function" href="functional__matrix__product_8hpp.html#aeb98bde348f8f5eb62e272fb771ce869">fm_prod</a>(<a class="code hl_function" href="functional__matrix__product_8hpp.html#aeb98bde348f8f5eb62e272fb771ce869">fm_prod</a>(X_lhs,W[i],m_number_threads),X_rhs,m_number_threads);</div>
<div class="line"><a id="l00360" name="l00360"></a><span class="lineno">  360</span> </div>
<div class="line"><a id="l00361" name="l00361"></a><span class="lineno">  361</span>        <span class="comment">//performing integration and multiplication with the penalty (inverse factorized)</span></div>
<div class="line"><a id="l00362" name="l00362"></a><span class="lineno">  362</span>        _operator_[i] = penalty[i].solve( fm_integration(integrand) ); </div>
<div class="line"><a id="l00363" name="l00363"></a><span class="lineno">  363</span>    }</div>
<div class="line"><a id="l00364" name="l00364"></a><span class="lineno">  364</span> </div>
<div class="line"><a id="l00365" name="l00365"></a><span class="lineno">  365</span>    <span class="keywordflow">return</span> _operator_;</div>
<div class="line"><a id="l00366" name="l00366"></a><span class="lineno">  366</span>}</div>
<div class="line"><a id="l00367" name="l00367"></a><span class="lineno">  367</span></div>
<div class="foldopen" id="foldopen00373" data-start="{" data-end="}">
<div class="line"><a id="l00373" name="l00373"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#a7d3e3832d6fbac64669ab9e0d2a5f2ac">  373</a></span><span class="comment">* @param W vector of functional diagonal matrices, containing, for each unit, functional weights</span></div>
<div class="line"><a id="l00374" name="l00374"></a><span class="lineno">  374</span><span class="comment">* @param X_rhs functional data matrix</span></div>
<div class="line"><a id="l00375" name="l00375"></a><span class="lineno">  375</span><span class="comment">* @param penalty vector of partial PivLU decomposition, containing the penalties [J_i + R]^(-1) as computed by the functions above</span></div>
<div class="line"><a id="l00376" name="l00376"></a><span class="lineno">  376</span><span class="comment">* @return a matrix containing the element-wise integration</span></div>
<div class="line"><a id="l00377" name="l00377"></a><span class="lineno">  377</span><span class="comment">*/</span></div>
<div class="line"><a id="l00378" name="l00378"></a><span class="lineno">  378</span><span class="keyword">template</span>&lt; <span class="keyword">typename</span> INPUT, <span class="keyword">typename</span> OUTPUT &gt;</div>
<div class="line"><a id="l00379" name="l00379"></a><span class="lineno">  379</span>    <span class="keyword">requires</span> (std::integral&lt;INPUT&gt; || std::floating_point&lt;INPUT&gt;)  &amp;&amp;  (std::integral&lt;OUTPUT&gt; || std::floating_point&lt;OUTPUT&gt;)</div>
<div class="line"><a id="l00380" name="l00380"></a><span class="lineno">  380</span>std::vector&lt; FDAGWR_TRAITS::Dense_Matrix &gt;</div>
<div class="foldopen" id="foldopen00381" data-start="{" data-end="}">
<div class="line"><a id="l00381" name="l00381"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#a347e8cf6b149f3edd93be4370c376e6d">  381</a></span><a class="code hl_function" href="classfwr__operator__computing.html#a20202c6ca2e008c6f37014232c9d8506">fwr_operator_computing&lt;INPUT,OUTPUT&gt;::compute_operator</a>(<span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix__sparse.html">functional_matrix_sparse&lt;INPUT,OUTPUT&gt;</a> &amp;base_lhs,</div>
<div class="line"><a id="l00382" name="l00382"></a><span class="lineno">  382</span>                                                       <span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> &amp;X_lhs,</div>
<div class="line"><a id="l00383" name="l00383"></a><span class="lineno">  383</span>                                                       <span class="keyword">const</span> std::vector&lt; <a class="code hl_class" href="classfunctional__matrix__diagonal.html">functional_matrix_diagonal&lt;INPUT,OUTPUT&gt;</a> &gt; &amp;W,</div>
<div class="line"><a id="l00384" name="l00384"></a><span class="lineno">  384</span>                                                       <span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> &amp;X_rhs,</div>
<div class="line"><a id="l00385" name="l00385"></a><span class="lineno">  385</span>                                                       <span class="keyword">const</span> std::vector&lt; Eigen::PartialPivLU&lt; FDAGWR_TRAITS::Dense_Matrix &gt; &gt; &amp;penalty)<span class="keyword"> </span></div>
<div class="line"><a id="l00386" name="l00386"></a><span class="lineno">  386</span><span class="keyword">const</span></div>
<div class="line"><a id="l00387" name="l00387"></a><span class="lineno">  387</span><span class="keyword"></span>{</div>
<div class="line"><a id="l00388" name="l00388"></a><span class="lineno">  388</span>    <span class="comment">//the vector contains factorization of the matrix</span></div>
<div class="line"><a id="l00389" name="l00389"></a><span class="lineno">  389</span>    std::vector&lt; FDAGWR_TRAITS::Dense_Matrix &gt; _operator_;</div>
<div class="foldopen" id="foldopen00390" data-start="{" data-end="}">
<div class="line"><a id="l00390" name="l00390"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#a24d06525c20434ebdf4ae0abd1c5f9a4">  390</a></span>    _operator_.resize(W.size());</div>
<div class="line"><a id="l00391" name="l00391"></a><span class="lineno">  391</span> </div>
<div class="line"><a id="l00392" name="l00392"></a><span class="lineno">  392</span><span class="preprocessor">#ifdef _OPENMP</span></div>
<div class="line"><a id="l00393" name="l00393"></a><span class="lineno">  393</span><span class="preprocessor">#pragma omp parallel for shared(_operator_,penalty,base_lhs,X_lhs,X_rhs,W,m_number_threads) num_threads(m_number_threads)</span></div>
<div class="line"><a id="l00394" name="l00394"></a><span class="lineno">  394</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l00395" name="l00395"></a><span class="lineno">  395</span>    <span class="keywordflow">for</span>(std::size_t i = 0; i &lt; W.size(); ++i)</div>
<div class="line"><a id="l00396" name="l00396"></a><span class="lineno">  396</span>    {       </div>
<div class="line"><a id="l00397" name="l00397"></a><span class="lineno">  397</span>        <span class="comment">//dimension: L_lhs x L_rhs, where L is the number of basis (the left basis is transpost)</span></div>
<div class="line"><a id="l00398" name="l00398"></a><span class="lineno">  398</span>        <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> integrand = <a class="code hl_function" href="functional__matrix__product_8hpp.html#aeb98bde348f8f5eb62e272fb771ce869">fm_prod</a>(<a class="code hl_function" href="functional__matrix__product_8hpp.html#aeb98bde348f8f5eb62e272fb771ce869">fm_prod</a>(<a class="code hl_function" href="functional__matrix__product_8hpp.html#aeb98bde348f8f5eb62e272fb771ce869">fm_prod</a>(base_lhs,X_lhs),W[i],m_number_threads),X_rhs,m_number_threads);</div>
<div class="line"><a id="l00399" name="l00399"></a><span class="lineno">  399</span> </div>
<div class="line"><a id="l00400" name="l00400"></a><span class="lineno">  400</span>        <span class="comment">//performing integration and multiplication with the penalty (inverse factorized)</span></div>
<div class="line"><a id="l00401" name="l00401"></a><span class="lineno">  401</span>        _operator_[i] = penalty[i].solve( fm_integration(integrand) ); </div>
<div class="line"><a id="l00402" name="l00402"></a><span class="lineno">  402</span>    }</div>
<div class="line"><a id="l00403" name="l00403"></a><span class="lineno">  403</span> </div>
<div class="line"><a id="l00404" name="l00404"></a><span class="lineno">  404</span>    <span class="keywordflow">return</span> _operator_;</div>
<div class="foldopen" id="foldopen00405" data-start="{" data-end="}">
<div class="line"><a id="l00405" name="l00405"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#a72e675a99e8c932900916ea64e1adaf2">  405</a></span>}</div>
<div class="line"><a id="l00406" name="l00406"></a><span class="lineno">  406</span></div>
<div class="line"><a id="l00415" name="l00415"></a><span class="lineno">  415</span><span class="keyword">template</span>&lt; <span class="keyword">typename</span> INPUT, <span class="keyword">typename</span> OUTPUT &gt;</div>
<div class="line"><a id="l00416" name="l00416"></a><span class="lineno">  416</span>    <span class="keyword">requires</span> (std::integral&lt;INPUT&gt; || std::floating_point&lt;INPUT&gt;)  &amp;&amp;  (std::integral&lt;OUTPUT&gt; || std::floating_point&lt;OUTPUT&gt;)</div>
<div class="foldopen" id="foldopen00417" data-start="{" data-end="}">
<div class="line"><a id="l00417" name="l00417"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#a4f01e517f32329c8355b33d4f56505d9">  417</a></span><a class="code hl_typedef" href="struct_f_d_a_g_w_r___t_r_a_i_t_s.html#a7480032013388cae40a69abf8d4ba297">FDAGWR_TRAITS::Dense_Matrix</a></div>
<div class="foldopen" id="foldopen00418" data-start="{" data-end="}">
<div class="line"><a id="l00418" name="l00418"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#a244d1696c290c92e368999c4ac7c50c1">  418</a></span><a class="code hl_function" href="classfwr__operator__computing.html#a20202c6ca2e008c6f37014232c9d8506">fwr_operator_computing&lt;INPUT,OUTPUT&gt;::compute_operator</a>(<span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> &amp;X_lhs,</div>
<div class="line"><a id="l00419" name="l00419"></a><span class="lineno">  419</span>                                                       <span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix__diagonal.html">functional_matrix_diagonal&lt;INPUT,OUTPUT&gt;</a> &amp;W,</div>
<div class="line"><a id="l00420" name="l00420"></a><span class="lineno">  420</span>                                                       <span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> &amp;X_rhs,</div>
<div class="line"><a id="l00421" name="l00421"></a><span class="lineno">  421</span>                                                       <span class="keyword">const</span> Eigen::PartialPivLU&lt; FDAGWR_TRAITS::Dense_Matrix &gt; &amp;penalty)<span class="keyword"> </span></div>
<div class="line"><a id="l00422" name="l00422"></a><span class="lineno">  422</span><span class="keyword">const</span></div>
<div class="line"><a id="l00423" name="l00423"></a><span class="lineno">  423</span><span class="keyword"></span>{</div>
<div class="line"><a id="l00424" name="l00424"></a><span class="lineno">  424</span>    <span class="comment">//dimension: L_lhs x L_rhs, where L is the number of basis (the left basis is transpost)</span></div>
<div class="line"><a id="l00425" name="l00425"></a><span class="lineno">  425</span>    <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> integrand = <a class="code hl_function" href="functional__matrix__product_8hpp.html#aeb98bde348f8f5eb62e272fb771ce869">fm_prod</a>(<a class="code hl_function" href="functional__matrix__product_8hpp.html#aeb98bde348f8f5eb62e272fb771ce869">fm_prod</a>(X_lhs,W,m_number_threads),X_rhs,m_number_threads);</div>
<div class="line"><a id="l00426" name="l00426"></a><span class="lineno">  426</span> </div>
<div class="line"><a id="l00427" name="l00427"></a><span class="lineno">  427</span>    <span class="comment">//performing integration and multiplication with the penalty (inverse factorized)</span></div>
<div class="line"><a id="l00428" name="l00428"></a><span class="lineno">  428</span>    <span class="keywordflow">return</span> penalty.solve( fm_integration(integrand) ); </div>
<div class="line"><a id="l00429" name="l00429"></a><span class="lineno">  429</span>}</div>
</div>
<div class="line"><a id="l00430" name="l00430"></a><span class="lineno">  430</span></div>
<div class="line"><a id="l00441" name="l00441"></a><span class="lineno">  441</span><span class="keyword">template</span>&lt; <span class="keyword">typename</span> INPUT, <span class="keyword">typename</span> OUTPUT &gt;</div>
<div class="line"><a id="l00442" name="l00442"></a><span class="lineno">  442</span>    <span class="keyword">requires</span> (std::integral&lt;INPUT&gt; || std::floating_point&lt;INPUT&gt;)  &amp;&amp;  (std::integral&lt;OUTPUT&gt; || std::floating_point&lt;OUTPUT&gt;)</div>
<div class="line"><a id="l00443" name="l00443"></a><span class="lineno">  443</span><a class="code hl_typedef" href="struct_f_d_a_g_w_r___t_r_a_i_t_s.html#a7480032013388cae40a69abf8d4ba297">FDAGWR_TRAITS::Dense_Matrix</a></div>
<div class="foldopen" id="foldopen00444" data-start="{" data-end="}">
<div class="line"><a id="l00444" name="l00444"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#a0639842962ed1aff6d1842d8ac4ad9b0">  444</a></span><a class="code hl_function" href="classfwr__operator__computing.html#a20202c6ca2e008c6f37014232c9d8506">fwr_operator_computing&lt;INPUT,OUTPUT&gt;::compute_operator</a>(<span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix__sparse.html">functional_matrix_sparse&lt;INPUT,OUTPUT&gt;</a> &amp;base_lhs,</div>
<div class="line"><a id="l00445" name="l00445"></a><span class="lineno">  445</span>                                                        <span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> &amp;X_lhs,</div>
<div class="line"><a id="l00446" name="l00446"></a><span class="lineno">  446</span>                                                        <span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix__diagonal.html">functional_matrix_diagonal&lt;INPUT,OUTPUT&gt;</a> &amp;W,</div>
<div class="line"><a id="l00447" name="l00447"></a><span class="lineno">  447</span>                                                        <span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> &amp;X_rhs,</div>
<div class="line"><a id="l00448" name="l00448"></a><span class="lineno">  448</span>                                                        <span class="keyword">const</span> Eigen::PartialPivLU&lt; FDAGWR_TRAITS::Dense_Matrix &gt; &amp;penalty)<span class="keyword"> </span></div>
<div class="line"><a id="l00449" name="l00449"></a><span class="lineno">  449</span><span class="keyword">const</span></div>
<div class="line"><a id="l00450" name="l00450"></a><span class="lineno">  450</span><span class="keyword"></span>{</div>
<div class="line"><a id="l00451" name="l00451"></a><span class="lineno">  451</span>    <span class="comment">//dimension: L_lhs x L_rhs, where L is the number of basis (the left basis is transpost)</span></div>
<div class="line"><a id="l00452" name="l00452"></a><span class="lineno">  452</span>    <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> integrand = <a class="code hl_function" href="functional__matrix__product_8hpp.html#aeb98bde348f8f5eb62e272fb771ce869">fm_prod</a>(<a class="code hl_function" href="functional__matrix__product_8hpp.html#aeb98bde348f8f5eb62e272fb771ce869">fm_prod</a>(<a class="code hl_function" href="functional__matrix__product_8hpp.html#aeb98bde348f8f5eb62e272fb771ce869">fm_prod</a>(base_lhs,X_lhs),W,m_number_threads),X_rhs,m_number_threads);</div>
<div class="line"><a id="l00453" name="l00453"></a><span class="lineno">  453</span> </div>
<div class="line"><a id="l00454" name="l00454"></a><span class="lineno">  454</span>    <span class="comment">//performing integration and multiplication with the penalty (inverse factorized)</span></div>
<div class="line"><a id="l00455" name="l00455"></a><span class="lineno">  455</span>    <span class="keywordflow">return</span> penalty.solve( fm_integration(integrand) ); </div>
<div class="line"><a id="l00456" name="l00456"></a><span class="lineno">  456</span>}</div>
</div>
<div class="line"><a id="l00457" name="l00457"></a><span class="lineno">  457</span></div>
<div class="line"><a id="l00466" name="l00466"></a><span class="lineno">  466</span><span class="keyword">template</span>&lt; <span class="keyword">typename</span> INPUT, <span class="keyword">typename</span> OUTPUT &gt;</div>
<div class="line"><a id="l00467" name="l00467"></a><span class="lineno">  467</span>    <span class="keyword">requires</span> (std::integral&lt;INPUT&gt; || std::floating_point&lt;INPUT&gt;)  &amp;&amp;  (std::integral&lt;OUTPUT&gt; || std::floating_point&lt;OUTPUT&gt;)</div>
<div class="line"><a id="l00468" name="l00468"></a><span class="lineno">  468</span><a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> </div>
<div class="foldopen" id="foldopen00469" data-start="{" data-end="}">
<div class="line"><a id="l00469" name="l00469"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#a2b15bc86a2d8daaef9934398adcd7116">  469</a></span><a class="code hl_function" href="classfwr__operator__computing.html#a2b15bc86a2d8daaef9934398adcd7116">fwr_operator_computing&lt;INPUT,OUTPUT&gt;::compute_functional_operator</a>(<span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> &amp;X,</div>
<div class="line"><a id="l00470" name="l00470"></a><span class="lineno">  470</span>                                                                   <span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix__sparse.html">functional_matrix_sparse&lt;INPUT,OUTPUT&gt;</a> &amp;base,</div>
<div class="line"><a id="l00471" name="l00471"></a><span class="lineno">  471</span>                                                                   <span class="keyword">const</span> std::vector&lt; FDAGWR_TRAITS::Dense_Matrix &gt; &amp;_operator_)<span class="keyword"> </span></div>
<div class="line"><a id="l00472" name="l00472"></a><span class="lineno">  472</span><span class="keyword">const</span></div>
<div class="line"><a id="l00473" name="l00473"></a><span class="lineno">  473</span><span class="keyword"></span>{</div>
<div class="line"><a id="l00474" name="l00474"></a><span class="lineno">  474</span>    <span class="comment">//number of rows of the functional operator</span></div>
<div class="line"><a id="l00475" name="l00475"></a><span class="lineno">  475</span>    std::size_t m = X.<a class="code hl_function" href="classfunctional__matrix.html#a08e1da679d37d9974ed71301cd894b85">rows</a>();</div>
<div class="line"><a id="l00476" name="l00476"></a><span class="lineno">  476</span>    <span class="comment">//number of cols of the functional operator</span></div>
<div class="line"><a id="l00477" name="l00477"></a><span class="lineno">  477</span>    std::size_t n = _operator_[0].cols();</div>
<div class="line"><a id="l00478" name="l00478"></a><span class="lineno">  478</span>    <span class="comment">//result</span></div>
<div class="line"><a id="l00479" name="l00479"></a><span class="lineno">  479</span>    <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> func_operator(m,n);</div>
<div class="line"><a id="l00480" name="l00480"></a><span class="lineno">  480</span> </div>
<div class="line"><a id="l00481" name="l00481"></a><span class="lineno">  481</span>    <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> x_times_base = <a class="code hl_function" href="functional__matrix__product_8hpp.html#aeb98bde348f8f5eb62e272fb771ce869">fm_prod</a>(X,base);</div>
<div class="line"><a id="l00482" name="l00482"></a><span class="lineno">  482</span> </div>
<div class="line"><a id="l00483" name="l00483"></a><span class="lineno">  483</span><span class="preprocessor">#ifdef _OPENMP</span></div>
<div class="line"><a id="l00484" name="l00484"></a><span class="lineno">  484</span><span class="preprocessor">#pragma omp parallel for shared(func_operator,x_times_base,_operator_,m,m_number_threads) num_threads(m_number_threads)</span></div>
<div class="line"><a id="l00485" name="l00485"></a><span class="lineno">  485</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l00486" name="l00486"></a><span class="lineno">  486</span>    <span class="keywordflow">for</span>(std::size_t i = 0; i &lt; m; ++i){</div>
<div class="line"><a id="l00487" name="l00487"></a><span class="lineno">  487</span>        <span class="comment">//trnasforming the scalar matrix into a functional one, with constant functions</span></div>
<div class="line"><a id="l00488" name="l00488"></a><span class="lineno">  488</span>        std::vector&lt; FUNC_OBJ&lt;INPUT,OUTPUT&gt; &gt; row_i_v(x_times_base.<a class="code hl_function" href="classfunctional__matrix.html#a2fe5a9c6e60487aa2939b40bf0a92b6f">row</a>(i).<a class="code hl_function" href="struct_row_view.html#a31a3024f41d57c24b1449787b120e535">cbegin</a>(),x_times_base.<a class="code hl_function" href="classfunctional__matrix.html#a2fe5a9c6e60487aa2939b40bf0a92b6f">row</a>(i).<a class="code hl_function" href="struct_row_view.html#abdcaf65a4f67f136927a95951f056d69">cend</a>());</div>
<div class="line"><a id="l00489" name="l00489"></a><span class="lineno">  489</span>        <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> row_i(row_i_v,1,base.<a class="code hl_function" href="classfunctional__matrix__sparse.html#a6cc0a36229ea306b7977158390d7b54a">cols</a>());</div>
<div class="line"><a id="l00490" name="l00490"></a><span class="lineno">  490</span>        <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> row_i_prod = <a class="code hl_function" href="functional__matrix__product_8hpp.html#aeb98bde348f8f5eb62e272fb771ce869">fm_prod</a>(row_i,_operator_[i],m_number_threads);</div>
<div class="line"><a id="l00491" name="l00491"></a><span class="lineno">  491</span>        func_operator.<a class="code hl_function" href="classfunctional__matrix.html#a0e1dff48be43aa434b76de3b9ab237fc">row_sub</a>(row_i_prod.<a class="code hl_function" href="classfunctional__matrix.html#a5a9eb8cced9b3dd9a83b98982aa8cf55">as_vector</a>(),i);</div>
<div class="line"><a id="l00492" name="l00492"></a><span class="lineno">  492</span>    }</div>
<div class="line"><a id="l00493" name="l00493"></a><span class="lineno">  493</span> </div>
<div class="line"><a id="l00494" name="l00494"></a><span class="lineno">  494</span>    <span class="keywordflow">return</span> func_operator;</div>
<div class="line"><a id="l00495" name="l00495"></a><span class="lineno">  495</span>}</div>
</div>
<div class="line"><a id="l00496" name="l00496"></a><span class="lineno">  496</span></div>
<div class="line"><a id="l00504" name="l00504"></a><span class="lineno">  504</span><span class="keyword">template</span>&lt; <span class="keyword">typename</span> INPUT, <span class="keyword">typename</span> OUTPUT &gt;</div>
<div class="line"><a id="l00505" name="l00505"></a><span class="lineno">  505</span>    <span class="keyword">requires</span> (std::integral&lt;INPUT&gt; || std::floating_point&lt;INPUT&gt;)  &amp;&amp;  (std::integral&lt;OUTPUT&gt; || std::floating_point&lt;OUTPUT&gt;)</div>
<div class="line"><a id="l00506" name="l00506"></a><span class="lineno">  506</span>std::vector&lt; FDAGWR_TRAITS::Dense_Matrix &gt;</div>
<div class="foldopen" id="foldopen00507" data-start="{" data-end="}">
<div class="line"><a id="l00507" name="l00507"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#a0f9fba8f012107fd443b687ba90b9886">  507</a></span><a class="code hl_function" href="classfwr__operator__computing.html#a0f9fba8f012107fd443b687ba90b9886">fwr_operator_computing&lt;INPUT,OUTPUT&gt;::wrap_operator</a>(<span class="keyword">const</span> <a class="code hl_typedef" href="struct_f_d_a_g_w_r___t_r_a_i_t_s.html#a7480032013388cae40a69abf8d4ba297">FDAGWR_TRAITS::Dense_Matrix</a>&amp; b,</div>
<div class="line"><a id="l00508" name="l00508"></a><span class="lineno">  508</span>                                                     <span class="keyword">const</span> std::vector&lt;std::size_t&gt;&amp; L_j,</div>
<div class="line"><a id="l00509" name="l00509"></a><span class="lineno">  509</span>                                                     std::size_t q)<span class="keyword"></span></div>
<div class="line"><a id="l00510" name="l00510"></a><span class="lineno">  510</span><span class="keyword">const</span></div>
<div class="line"><a id="l00511" name="l00511"></a><span class="lineno">  511</span><span class="keyword"></span>{</div>
<div class="line"><a id="l00512" name="l00512"></a><span class="lineno">  512</span>    <span class="comment">//input coherency</span></div>
<div class="line"><a id="l00513" name="l00513"></a><span class="lineno">  513</span>    assert((L_j.size() == q) &amp;&amp; (b.cols() == 1) &amp;&amp; (b.rows() == std::reduce(L_j.cbegin(),L_j.cend(),<span class="keyword">static_cast&lt;</span>std::size_t<span class="keyword">&gt;</span>(0))));</div>
<div class="line"><a id="l00514" name="l00514"></a><span class="lineno">  514</span>    <span class="comment">//container</span></div>
<div class="line"><a id="l00515" name="l00515"></a><span class="lineno">  515</span>    std::vector&lt; FDAGWR_TRAITS::Dense_Matrix &gt; B;</div>
<div class="line"><a id="l00516" name="l00516"></a><span class="lineno">  516</span>    B.reserve(q);</div>
<div class="line"><a id="l00517" name="l00517"></a><span class="lineno">  517</span>    <span class="keywordflow">for</span>(std::size_t j = 0; j &lt; q; ++j)</div>
<div class="line"><a id="l00518" name="l00518"></a><span class="lineno">  518</span>    {</div>
<div class="line"><a id="l00519" name="l00519"></a><span class="lineno">  519</span>        <span class="comment">//for each stationary covariates</span></div>
<div class="line"><a id="l00520" name="l00520"></a><span class="lineno">  520</span>        std::size_t start_idx = std::reduce(L_j.cbegin(),std::next(L_j.cbegin(),j),<span class="keyword">static_cast&lt;</span>std::size_t<span class="keyword">&gt;</span>(0));</div>
<div class="line"><a id="l00521" name="l00521"></a><span class="lineno">  521</span>        <span class="comment">//taking the right coefficients of the basis expansion</span></div>
<div class="line"><a id="l00522" name="l00522"></a><span class="lineno">  522</span>        <a class="code hl_typedef" href="struct_f_d_a_g_w_r___t_r_a_i_t_s.html#a7480032013388cae40a69abf8d4ba297">FDAGWR_TRAITS::Dense_Matrix</a> B_j = b.block(start_idx,0,L_j[j],1);</div>
<div class="line"><a id="l00523" name="l00523"></a><span class="lineno">  523</span>        B.push_back(B_j);</div>
<div class="line"><a id="l00524" name="l00524"></a><span class="lineno">  524</span>    }</div>
<div class="line"><a id="l00525" name="l00525"></a><span class="lineno">  525</span> </div>
<div class="line"><a id="l00526" name="l00526"></a><span class="lineno">  526</span>    <span class="keywordflow">return</span> B;</div>
<div class="line"><a id="l00527" name="l00527"></a><span class="lineno">  527</span>}</div>
</div>
<div class="line"><a id="l00528" name="l00528"></a><span class="lineno">  528</span></div>
<div class="line"><a id="l00537" name="l00537"></a><span class="lineno">  537</span><span class="keyword">template</span>&lt; <span class="keyword">typename</span> INPUT, <span class="keyword">typename</span> OUTPUT &gt;</div>
<div class="line"><a id="l00538" name="l00538"></a><span class="lineno">  538</span>    <span class="keyword">requires</span> (std::integral&lt;INPUT&gt; || std::floating_point&lt;INPUT&gt;)  &amp;&amp;  (std::integral&lt;OUTPUT&gt; || std::floating_point&lt;OUTPUT&gt;)</div>
<div class="line"><a id="l00539" name="l00539"></a><span class="lineno">  539</span>std::vector&lt; std::vector&lt; FDAGWR_TRAITS::Dense_Matrix &gt; &gt;</div>
<div class="foldopen" id="foldopen00540" data-start="{" data-end="}">
<div class="line"><a id="l00540" name="l00540"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#a5a6ab857c0278a75a5b97b9496603de0">  540</a></span><a class="code hl_function" href="classfwr__operator__computing.html#a0f9fba8f012107fd443b687ba90b9886">fwr_operator_computing&lt;INPUT,OUTPUT&gt;::wrap_operator</a>(<span class="keyword">const</span> std::vector&lt; FDAGWR_TRAITS::Dense_Matrix &gt;&amp; b,</div>
<div class="line"><a id="l00541" name="l00541"></a><span class="lineno">  541</span>                                                     <span class="keyword">const</span> std::vector&lt;std::size_t&gt;&amp; L_j,</div>
<div class="line"><a id="l00542" name="l00542"></a><span class="lineno">  542</span>                                                     std::size_t q,</div>
<div class="line"><a id="l00543" name="l00543"></a><span class="lineno">  543</span>                                                     std::size_t n)<span class="keyword"> </span></div>
<div class="line"><a id="l00544" name="l00544"></a><span class="lineno">  544</span><span class="keyword">const</span></div>
<div class="line"><a id="l00545" name="l00545"></a><span class="lineno">  545</span><span class="keyword"></span>{</div>
<div class="line"><a id="l00546" name="l00546"></a><span class="lineno">  546</span>    <span class="comment">//n is the number of units for training</span></div>
<div class="line"><a id="l00547" name="l00547"></a><span class="lineno">  547</span>    <span class="comment">//input coherency</span></div>
<div class="line"><a id="l00548" name="l00548"></a><span class="lineno">  548</span>    assert((b.size() == n) &amp;&amp; (L_j.size() == q));</div>
<div class="line"><a id="l00549" name="l00549"></a><span class="lineno">  549</span>    <span class="keywordflow">for</span>(std::size_t i = 0; i &lt; b.size(); ++i){     assert((b[i].cols() == 1) &amp;&amp; (b[i].rows() == std::reduce(L_j.cbegin(),L_j.cend(),<span class="keyword">static_cast&lt;</span>std::size_t<span class="keyword">&gt;</span>(0))));}</div>
<div class="line"><a id="l00550" name="l00550"></a><span class="lineno">  550</span>    <span class="comment">//container</span></div>
<div class="line"><a id="l00551" name="l00551"></a><span class="lineno">  551</span>    std::vector&lt; std::vector&lt; FDAGWR_TRAITS::Dense_Matrix &gt;&gt; B;    </div>
<div class="line"><a id="l00552" name="l00552"></a><span class="lineno">  552</span>    B.reserve(q);</div>
<div class="line"><a id="l00553" name="l00553"></a><span class="lineno">  553</span>    <span class="keywordflow">for</span>(std::size_t j = 0; j &lt; q; ++j)</div>
<div class="line"><a id="l00554" name="l00554"></a><span class="lineno">  554</span>    {</div>
<div class="line"><a id="l00555" name="l00555"></a><span class="lineno">  555</span>        <span class="comment">//for each event-dependent covariates</span></div>
<div class="line"><a id="l00556" name="l00556"></a><span class="lineno">  556</span>        std::size_t start_idx = std::reduce(L_j.cbegin(),std::next(L_j.cbegin(),j),<span class="keyword">static_cast&lt;</span>std::size_t<span class="keyword">&gt;</span>(0));</div>
<div class="line"><a id="l00557" name="l00557"></a><span class="lineno">  557</span>        std::vector&lt; FDAGWR_TRAITS::Dense_Matrix &gt; B_j;</div>
<div class="line"><a id="l00558" name="l00558"></a><span class="lineno">  558</span>        B_j.reserve(b.size());</div>
<div class="line"><a id="l00559" name="l00559"></a><span class="lineno">  559</span>        <span class="comment">//for all the units</span></div>
<div class="line"><a id="l00560" name="l00560"></a><span class="lineno">  560</span>        <span class="keywordflow">for</span>(std::size_t i = 0; i &lt; b.size(); ++i){</div>
<div class="line"><a id="l00561" name="l00561"></a><span class="lineno">  561</span>            <span class="comment">//taking the right coefficients of the basis expansion</span></div>
<div class="line"><a id="l00562" name="l00562"></a><span class="lineno">  562</span>            <a class="code hl_typedef" href="struct_f_d_a_g_w_r___t_r_a_i_t_s.html#a7480032013388cae40a69abf8d4ba297">FDAGWR_TRAITS::Dense_Matrix</a> B_j_i = b[i].block(start_idx,0,L_j[j],1);</div>
<div class="line"><a id="l00563" name="l00563"></a><span class="lineno">  563</span>            B_j.push_back(B_j_i);}</div>
<div class="line"><a id="l00564" name="l00564"></a><span class="lineno">  564</span>        B.push_back(B_j);</div>
<div class="line"><a id="l00565" name="l00565"></a><span class="lineno">  565</span>    }</div>
<div class="line"><a id="l00566" name="l00566"></a><span class="lineno">  566</span> </div>
<div class="line"><a id="l00567" name="l00567"></a><span class="lineno">  567</span>    <span class="keywordflow">return</span> B;</div>
<div class="line"><a id="l00568" name="l00568"></a><span class="lineno">  568</span>}</div>
</div>
<div class="line"><a id="l00569" name="l00569"></a><span class="lineno">  569</span></div>
<div class="line"><a id="l00576" name="l00576"></a><span class="lineno">  576</span><span class="keyword">template</span>&lt; <span class="keyword">typename</span> INPUT, <span class="keyword">typename</span> OUTPUT &gt;</div>
<div class="line"><a id="l00577" name="l00577"></a><span class="lineno">  577</span>    <span class="keyword">requires</span> (std::integral&lt;INPUT&gt; || std::floating_point&lt;INPUT&gt;)  &amp;&amp;  (std::integral&lt;OUTPUT&gt; || std::floating_point&lt;OUTPUT&gt;)</div>
<div class="line"><a id="l00578" name="l00578"></a><span class="lineno">  578</span><a class="code hl_typedef" href="struct_f_d_a_g_w_r___t_r_a_i_t_s.html#a7480032013388cae40a69abf8d4ba297">FDAGWR_TRAITS::Dense_Matrix</a> </div>
<div class="foldopen" id="foldopen00579" data-start="{" data-end="}">
<div class="line"><a id="l00579" name="l00579"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#ab63b635a1edc829c2652e54a66f446b2">  579</a></span><a class="code hl_function" href="classfwr__operator__computing.html#ab63b635a1edc829c2652e54a66f446b2">fwr_operator_computing&lt;INPUT,OUTPUT&gt;::dewrap_operator</a>(<span class="keyword">const</span> std::vector&lt; FDAGWR_TRAITS::Dense_Matrix &gt;&amp; b,</div>
<div class="line"><a id="l00580" name="l00580"></a><span class="lineno">  580</span>                                                       <span class="keyword">const</span> std::vector&lt;std::size_t&gt;&amp; L_j)<span class="keyword"> </span></div>
<div class="line"><a id="l00581" name="l00581"></a><span class="lineno">  581</span><span class="keyword">const</span></div>
<div class="line"><a id="l00582" name="l00582"></a><span class="lineno">  582</span><span class="keyword"></span>{</div>
<div class="line"><a id="l00583" name="l00583"></a><span class="lineno">  583</span>    <span class="comment">//input coherency</span></div>
<div class="line"><a id="l00584" name="l00584"></a><span class="lineno">  584</span>    assert(b.size() == L_j.size());</div>
<div class="line"><a id="l00585" name="l00585"></a><span class="lineno">  585</span>    <span class="keywordflow">for</span>(std::size_t i = 0; i &lt; b.size(); ++i){  assert((b[i].cols()==1) &amp;&amp; (b[i].rows()==L_j[i]));}</div>
<div class="line"><a id="l00586" name="l00586"></a><span class="lineno">  586</span> </div>
<div class="line"><a id="l00587" name="l00587"></a><span class="lineno">  587</span>    <a class="code hl_typedef" href="struct_f_d_a_g_w_r___t_r_a_i_t_s.html#a7480032013388cae40a69abf8d4ba297">FDAGWR_TRAITS::Dense_Matrix</a> b_dewrapped(std::reduce(L_j.cbegin(),L_j.cend(),<span class="keyword">static_cast&lt;</span>std::size_t<span class="keyword">&gt;</span>(0)),1);</div>
<div class="line"><a id="l00588" name="l00588"></a><span class="lineno">  588</span> </div>
<div class="line"><a id="l00589" name="l00589"></a><span class="lineno">  589</span>    <span class="keywordflow">for</span>(std::size_t j = 0; j &lt; L_j.size(); ++j)</div>
<div class="line"><a id="l00590" name="l00590"></a><span class="lineno">  590</span>    {</div>
<div class="line"><a id="l00591" name="l00591"></a><span class="lineno">  591</span>        std::size_t start_idx = std::reduce(L_j.cbegin(),std::next(L_j.cbegin(),j),<span class="keyword">static_cast&lt;</span>std::size_t<span class="keyword">&gt;</span>(0));</div>
<div class="line"><a id="l00592" name="l00592"></a><span class="lineno">  592</span>        b_dewrapped.block(start_idx,0,L_j[j],1) = b[j];</div>
<div class="line"><a id="l00593" name="l00593"></a><span class="lineno">  593</span>    }</div>
<div class="line"><a id="l00594" name="l00594"></a><span class="lineno">  594</span> </div>
<div class="line"><a id="l00595" name="l00595"></a><span class="lineno">  595</span>    <span class="keywordflow">return</span> b_dewrapped;</div>
<div class="line"><a id="l00596" name="l00596"></a><span class="lineno">  596</span>}</div>
</div>
<div class="line"><a id="l00597" name="l00597"></a><span class="lineno">  597</span></div>
<div class="line"><a id="l00605" name="l00605"></a><span class="lineno">  605</span><span class="keyword">template</span>&lt; <span class="keyword">typename</span> INPUT, <span class="keyword">typename</span> OUTPUT &gt;</div>
<div class="line"><a id="l00606" name="l00606"></a><span class="lineno">  606</span>    <span class="keyword">requires</span> (std::integral&lt;INPUT&gt; || std::floating_point&lt;INPUT&gt;)  &amp;&amp;  (std::integral&lt;OUTPUT&gt; || std::floating_point&lt;OUTPUT&gt;)</div>
<div class="line"><a id="l00607" name="l00607"></a><span class="lineno">  607</span>std::vector&lt; FDAGWR_TRAITS::Dense_Matrix &gt;</div>
<div class="foldopen" id="foldopen00608" data-start="{" data-end="}">
<div class="line"><a id="l00608" name="l00608"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#ab3120096261e2ba6c7536b9006dc3419">  608</a></span><a class="code hl_function" href="classfwr__operator__computing.html#ab63b635a1edc829c2652e54a66f446b2">fwr_operator_computing&lt;INPUT,OUTPUT&gt;::dewrap_operator</a>(<span class="keyword">const</span> std::vector&lt; std::vector&lt; FDAGWR_TRAITS::Dense_Matrix &gt;&gt;&amp; b,</div>
<div class="line"><a id="l00609" name="l00609"></a><span class="lineno">  609</span>                                                       <span class="keyword">const</span> std::vector&lt;std::size_t&gt;&amp; L_j,</div>
<div class="line"><a id="l00610" name="l00610"></a><span class="lineno">  610</span>                                                       std::size_t n)<span class="keyword"> </span></div>
<div class="line"><a id="l00611" name="l00611"></a><span class="lineno">  611</span><span class="keyword">const</span></div>
<div class="line"><a id="l00612" name="l00612"></a><span class="lineno">  612</span><span class="keyword"></span>{</div>
<div class="line"><a id="l00613" name="l00613"></a><span class="lineno">  613</span>    <span class="comment">//input coherency</span></div>
<div class="line"><a id="l00614" name="l00614"></a><span class="lineno">  614</span>    assert(b.size() == L_j.size());</div>
<div class="line"><a id="l00615" name="l00615"></a><span class="lineno">  615</span>    std::size_t q = L_j.size();</div>
<div class="line"><a id="l00616" name="l00616"></a><span class="lineno">  616</span>    <span class="keywordflow">for</span>(std::size_t j = 0; j &lt; q; ++j){ assert(b[j].size() == n);}</div>
<div class="line"><a id="l00617" name="l00617"></a><span class="lineno">  617</span> </div>
<div class="line"><a id="l00618" name="l00618"></a><span class="lineno">  618</span>    std::vector&lt; FDAGWR_TRAITS::Dense_Matrix &gt; b_dewrapped;</div>
<div class="line"><a id="l00619" name="l00619"></a><span class="lineno">  619</span>    b_dewrapped.reserve(n);</div>
<div class="line"><a id="l00620" name="l00620"></a><span class="lineno">  620</span> </div>
<div class="line"><a id="l00621" name="l00621"></a><span class="lineno">  621</span>    <span class="keywordflow">for</span>(std::size_t i = 0; i &lt; n; ++i){</div>
<div class="line"><a id="l00622" name="l00622"></a><span class="lineno">  622</span> </div>
<div class="line"><a id="l00623" name="l00623"></a><span class="lineno">  623</span>        std::vector&lt; FDAGWR_TRAITS::Dense_Matrix &gt; b_i;</div>
<div class="line"><a id="l00624" name="l00624"></a><span class="lineno">  624</span>        b_i.reserve(q);</div>
<div class="line"><a id="l00625" name="l00625"></a><span class="lineno">  625</span>        <span class="keywordflow">for</span>(std::size_t j = 0; j &lt; q; ++j){     b_i.push_back(b[j][i]);}</div>
<div class="line"><a id="l00626" name="l00626"></a><span class="lineno">  626</span>        b_dewrapped.push_back(this-&gt;<a class="code hl_function" href="classfwr__operator__computing.html#ab63b635a1edc829c2652e54a66f446b2">dewrap_operator</a>(b_i,L_j));</div>
<div class="line"><a id="l00627" name="l00627"></a><span class="lineno">  627</span>    }</div>
<div class="line"><a id="l00628" name="l00628"></a><span class="lineno">  628</span> </div>
<div class="line"><a id="l00629" name="l00629"></a><span class="lineno">  629</span>    <span class="keywordflow">return</span> b_dewrapped;</div>
<div class="line"><a id="l00630" name="l00630"></a><span class="lineno">  630</span>}</div>
</div>
<div class="line"><a id="l00631" name="l00631"></a><span class="lineno">  631</span></div>
<div class="line"><a id="l00641" name="l00641"></a><span class="lineno">  641</span><span class="keyword">template</span>&lt; <span class="keyword">typename</span> INPUT, <span class="keyword">typename</span> OUTPUT &gt;</div>
<div class="line"><a id="l00642" name="l00642"></a><span class="lineno">  642</span>    <span class="keyword">requires</span> (std::integral&lt;INPUT&gt; || std::floating_point&lt;INPUT&gt;)  &amp;&amp;  (std::integral&lt;OUTPUT&gt; || std::floating_point&lt;OUTPUT&gt;)</div>
<div class="line"><a id="l00643" name="l00643"></a><span class="lineno">  643</span>std::vector&lt; std::vector&lt; OUTPUT &gt;&gt;</div>
<div class="foldopen" id="foldopen00644" data-start="{" data-end="}">
<div class="line"><a id="l00644" name="l00644"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#a7d3e3832d6fbac64669ab9e0d2a5f2ac">  644</a></span><a class="code hl_function" href="classfwr__operator__computing.html#a7d3e3832d6fbac64669ab9e0d2a5f2ac">fwr_operator_computing&lt;INPUT,OUTPUT&gt;::eval_func_betas</a>(<span class="keyword">const</span> std::vector&lt; FDAGWR_TRAITS::Dense_Matrix &gt;&amp; B,</div>
<div class="line"><a id="l00645" name="l00645"></a><span class="lineno">  645</span>                                                      <span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix__sparse.html">functional_matrix_sparse&lt;INPUT,OUTPUT&gt;</a>&amp; basis_B,</div>
<div class="line"><a id="l00646" name="l00646"></a><span class="lineno">  646</span>                                                      <span class="keyword">const</span> std::vector&lt;std::size_t&gt;&amp; L_j,</div>
<div class="line"><a id="l00647" name="l00647"></a><span class="lineno">  647</span>                                                      std::size_t q,</div>
<div class="line"><a id="l00648" name="l00648"></a><span class="lineno">  648</span>                                                      <span class="keyword">const</span> std::vector&lt; INPUT &gt;&amp; abscissas)<span class="keyword"> </span></div>
<div class="line"><a id="l00649" name="l00649"></a><span class="lineno">  649</span><span class="keyword">const</span></div>
<div class="line"><a id="l00650" name="l00650"></a><span class="lineno">  650</span><span class="keyword"></span>{</div>
<div class="line"><a id="l00651" name="l00651"></a><span class="lineno">  651</span>    </div>
<div class="line"><a id="l00652" name="l00652"></a><span class="lineno">  652</span>    <span class="comment">//input coherency</span></div>
<div class="line"><a id="l00653" name="l00653"></a><span class="lineno">  653</span>    assert((B.size() == q) &amp;&amp; (L_j.size() == q) &amp;&amp; (basis_B.<a class="code hl_function" href="classfunctional__matrix__sparse.html#a2e658bd50a637ceab3a30ad7391ccf33">rows</a>() == q) &amp;&amp; (basis_B.<a class="code hl_function" href="classfunctional__matrix__sparse.html#a6cc0a36229ea306b7977158390d7b54a">cols</a>() == std::reduce(L_j.cbegin(),L_j.cend(),<span class="keyword">static_cast&lt;</span>std::size_t<span class="keyword">&gt;</span>(0))));</div>
<div class="line"><a id="l00654" name="l00654"></a><span class="lineno">  654</span>    <span class="keywordflow">for</span>(std::size_t j = 0; j &lt; q; ++j){     assert((B[j].rows() == L_j[j]) &amp;&amp; (B[j].cols() == 1));}</div>
<div class="line"><a id="l00655" name="l00655"></a><span class="lineno">  655</span>    <span class="comment">//container</span></div>
<div class="line"><a id="l00656" name="l00656"></a><span class="lineno">  656</span>    std::vector&lt; std::vector&lt; OUTPUT &gt;&gt; beta;</div>
<div class="line"><a id="l00657" name="l00657"></a><span class="lineno">  657</span>    beta.reserve(B.size());</div>
<div class="line"><a id="l00658" name="l00658"></a><span class="lineno">  658</span>    <span class="comment">//aliases</span></div>
<div class="line"><a id="l00659" name="l00659"></a><span class="lineno">  659</span>    <span class="keyword">using </span>F_OBJ = <a class="code hl_typedef" href="functional__matrix__storing__type_8hpp.html#a70bd7133abb8b1da57ebdefc24d861b0">FUNC_OBJ&lt;INPUT,OUTPUT&gt;</a>;</div>
<div class="line"><a id="l00660" name="l00660"></a><span class="lineno">  660</span>    <span class="keyword">using </span>F_OBJ_INPUT = <a class="code hl_typedef" href="namespacefm__utils.html#a748f7d067be88eb04e84183231471d39">fm_utils::input_param_t&lt;F_OBJ&gt;</a>;</div>
<div class="line"><a id="l00661" name="l00661"></a><span class="lineno">  661</span> </div>
<div class="line"><a id="l00662" name="l00662"></a><span class="lineno">  662</span>    <span class="keywordflow">for</span>(std::size_t j = 0; j &lt; B.size(); ++j)</div>
<div class="line"><a id="l00663" name="l00663"></a><span class="lineno">  663</span>    {</div>
<div class="line"><a id="l00664" name="l00664"></a><span class="lineno">  664</span>        <span class="comment">//retrieving the basis</span></div>
<div class="line"><a id="l00665" name="l00665"></a><span class="lineno">  665</span>        std::vector&lt; F_OBJ &gt; basis_j_v;</div>
<div class="line"><a id="l00666" name="l00666"></a><span class="lineno">  666</span>        basis_j_v.reserve(B[j].rows());</div>
<div class="line"><a id="l00667" name="l00667"></a><span class="lineno">  667</span>        std::size_t start_idx = std::reduce(L_j.cbegin(),std::next(L_j.cbegin(),j),<span class="keyword">static_cast&lt;</span>std::size_t<span class="keyword">&gt;</span>(0));</div>
<div class="line"><a id="l00668" name="l00668"></a><span class="lineno">  668</span>        std::size_t end_idx = start_idx + L_j[j];</div>
<div class="line"><a id="l00669" name="l00669"></a><span class="lineno">  669</span>        <span class="keywordflow">for</span>(std::size_t k = start_idx; k &lt; end_idx; ++k){   basis_j_v.push_back(basis_B(j,k));}</div>
<div class="line"><a id="l00670" name="l00670"></a><span class="lineno">  670</span>        <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> basis_j(basis_j_v,1,B[j].rows());</div>
<div class="line"><a id="l00671" name="l00671"></a><span class="lineno">  671</span> </div>
<div class="line"><a id="l00672" name="l00672"></a><span class="lineno">  672</span>        <span class="comment">//compute the beta</span></div>
<div class="line"><a id="l00673" name="l00673"></a><span class="lineno">  673</span>        <a class="code hl_typedef" href="functional__matrix__storing__type_8hpp.html#a70bd7133abb8b1da57ebdefc24d861b0">FUNC_OBJ&lt;INPUT,OUTPUT&gt;</a> beta_j = <a class="code hl_function" href="functional__matrix__product_8hpp.html#aeb98bde348f8f5eb62e272fb771ce869">fm_prod&lt;INPUT,OUTPUT&gt;</a>(basis_j,B[j],m_number_threads)(0,0);</div>
<div class="line"><a id="l00674" name="l00674"></a><span class="lineno">  674</span>        <span class="comment">//eval the beta</span></div>
<div class="line"><a id="l00675" name="l00675"></a><span class="lineno">  675</span>        std::vector&lt; OUTPUT &gt; beta_j_ev; </div>
<div class="line"><a id="l00676" name="l00676"></a><span class="lineno">  676</span>        beta_j_ev.resize(abscissas.size());</div>
<div class="line"><a id="l00677" name="l00677"></a><span class="lineno">  677</span>        std::transform(abscissas.cbegin(),abscissas.cend(),beta_j_ev.begin(),[&amp;beta_j](F_OBJ_INPUT x){return beta_j(x);});</div>
<div class="line"><a id="l00678" name="l00678"></a><span class="lineno">  678</span>        beta.push_back(beta_j_ev);</div>
<div class="line"><a id="l00679" name="l00679"></a><span class="lineno">  679</span>    }</div>
<div class="line"><a id="l00680" name="l00680"></a><span class="lineno">  680</span> </div>
<div class="line"><a id="l00681" name="l00681"></a><span class="lineno">  681</span>    <span class="keywordflow">return</span> beta;</div>
<div class="line"><a id="l00682" name="l00682"></a><span class="lineno">  682</span>}</div>
</div>
<div class="line"><a id="l00683" name="l00683"></a><span class="lineno">  683</span></div>
<div class="line"><a id="l00694" name="l00694"></a><span class="lineno">  694</span><span class="keyword">template</span>&lt; <span class="keyword">typename</span> INPUT, <span class="keyword">typename</span> OUTPUT &gt;</div>
<div class="line"><a id="l00695" name="l00695"></a><span class="lineno">  695</span>    <span class="keyword">requires</span> (std::integral&lt;INPUT&gt; || std::floating_point&lt;INPUT&gt;)  &amp;&amp;  (std::integral&lt;OUTPUT&gt; || std::floating_point&lt;OUTPUT&gt;)</div>
<div class="line"><a id="l00696" name="l00696"></a><span class="lineno">  696</span>std::vector&lt; std::vector&lt; std::vector&lt; OUTPUT &gt;&gt;&gt;</div>
<div class="foldopen" id="foldopen00697" data-start="{" data-end="}">
<div class="line"><a id="l00697" name="l00697"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#a24d06525c20434ebdf4ae0abd1c5f9a4">  697</a></span><a class="code hl_function" href="classfwr__operator__computing.html#a7d3e3832d6fbac64669ab9e0d2a5f2ac">fwr_operator_computing&lt;INPUT,OUTPUT&gt;::eval_func_betas</a>(<span class="keyword">const</span> std::vector&lt; std::vector&lt; FDAGWR_TRAITS::Dense_Matrix &gt;&gt;&amp; B,</div>
<div class="line"><a id="l00698" name="l00698"></a><span class="lineno">  698</span>                                                      <span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix__sparse.html">functional_matrix_sparse&lt;INPUT,OUTPUT&gt;</a>&amp; basis_B,</div>
<div class="line"><a id="l00699" name="l00699"></a><span class="lineno">  699</span>                                                      <span class="keyword">const</span> std::vector&lt;std::size_t&gt;&amp; L_j,</div>
<div class="line"><a id="l00700" name="l00700"></a><span class="lineno">  700</span>                                                      std::size_t q,</div>
<div class="line"><a id="l00701" name="l00701"></a><span class="lineno">  701</span>                                                      std::size_t n,</div>
<div class="line"><a id="l00702" name="l00702"></a><span class="lineno">  702</span>                                                      <span class="keyword">const</span> std::vector&lt; INPUT &gt;&amp; abscissas)<span class="keyword"></span></div>
<div class="line"><a id="l00703" name="l00703"></a><span class="lineno">  703</span><span class="keyword">const</span></div>
<div class="line"><a id="l00704" name="l00704"></a><span class="lineno">  704</span><span class="keyword"></span>{</div>
<div class="line"><a id="l00705" name="l00705"></a><span class="lineno">  705</span>    <span class="comment">//input coherency</span></div>
<div class="line"><a id="l00706" name="l00706"></a><span class="lineno">  706</span>    assert((B.size() == q) &amp;&amp; (L_j.size() == q) &amp;&amp; (basis_B.<a class="code hl_function" href="classfunctional__matrix__sparse.html#a2e658bd50a637ceab3a30ad7391ccf33">rows</a>() == q) &amp;&amp; (basis_B.<a class="code hl_function" href="classfunctional__matrix__sparse.html#a6cc0a36229ea306b7977158390d7b54a">cols</a>() == std::reduce(L_j.cbegin(),L_j.cend(),<span class="keyword">static_cast&lt;</span>std::size_t<span class="keyword">&gt;</span>(0))));</div>
<div class="line"><a id="l00707" name="l00707"></a><span class="lineno">  707</span>    <span class="keywordflow">for</span>(std::size_t j = 0; j &lt; B.size(); ++j){  </div>
<div class="line"><a id="l00708" name="l00708"></a><span class="lineno">  708</span>        assert(B[j].size() == n);   </div>
<div class="line"><a id="l00709" name="l00709"></a><span class="lineno">  709</span>        <span class="keywordflow">for</span>(std::size_t i = 0; i &lt; B[j].size(); ++i){     assert((B[j][i].rows() == L_j[j]) &amp;&amp; (B[j][i].cols() == 1));}}</div>
<div class="line"><a id="l00710" name="l00710"></a><span class="lineno">  710</span>        </div>
<div class="line"><a id="l00711" name="l00711"></a><span class="lineno">  711</span>    <span class="comment">//container</span></div>
<div class="line"><a id="l00712" name="l00712"></a><span class="lineno">  712</span>    std::vector&lt; std::vector&lt; std::vector&lt; OUTPUT &gt;&gt;&gt; beta;</div>
<div class="line"><a id="l00713" name="l00713"></a><span class="lineno">  713</span>    beta.reserve(B.size());</div>
<div class="line"><a id="l00714" name="l00714"></a><span class="lineno">  714</span>    <span class="comment">//aliases</span></div>
<div class="line"><a id="l00715" name="l00715"></a><span class="lineno">  715</span>    <span class="keyword">using </span>F_OBJ = <a class="code hl_typedef" href="functional__matrix__storing__type_8hpp.html#a70bd7133abb8b1da57ebdefc24d861b0">FUNC_OBJ&lt;INPUT,OUTPUT&gt;</a>;</div>
<div class="line"><a id="l00716" name="l00716"></a><span class="lineno">  716</span>    <span class="keyword">using </span>F_OBJ_INPUT = <a class="code hl_typedef" href="namespacefm__utils.html#a748f7d067be88eb04e84183231471d39">fm_utils::input_param_t&lt;F_OBJ&gt;</a>;</div>
<div class="line"><a id="l00717" name="l00717"></a><span class="lineno">  717</span>    </div>
<div class="line"><a id="l00718" name="l00718"></a><span class="lineno">  718</span> </div>
<div class="line"><a id="l00719" name="l00719"></a><span class="lineno">  719</span>    <span class="keywordflow">for</span>(std::size_t j = 0; j &lt; B.size(); ++j)</div>
<div class="line"><a id="l00720" name="l00720"></a><span class="lineno">  720</span>    {</div>
<div class="line"><a id="l00721" name="l00721"></a><span class="lineno">  721</span>        <span class="comment">//retrieving the basis</span></div>
<div class="line"><a id="l00722" name="l00722"></a><span class="lineno">  722</span>        std::vector&lt; F_OBJ &gt; basis_j_v;</div>
<div class="line"><a id="l00723" name="l00723"></a><span class="lineno">  723</span>        basis_j_v.reserve(L_j[j]);</div>
<div class="line"><a id="l00724" name="l00724"></a><span class="lineno">  724</span>        std::size_t start_idx = std::reduce(L_j.cbegin(),std::next(L_j.cbegin(),j),<span class="keyword">static_cast&lt;</span>std::size_t<span class="keyword">&gt;</span>(0));</div>
<div class="line"><a id="l00725" name="l00725"></a><span class="lineno">  725</span>        std::size_t end_idx = start_idx + L_j[j];</div>
<div class="line"><a id="l00726" name="l00726"></a><span class="lineno">  726</span>        <span class="keywordflow">for</span>(std::size_t k = start_idx; k &lt; end_idx; ++k){   basis_j_v.push_back(basis_B(j,k));}</div>
<div class="line"><a id="l00727" name="l00727"></a><span class="lineno">  727</span>        <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> basis_j(basis_j_v,1,L_j[j]);</div>
<div class="line"><a id="l00728" name="l00728"></a><span class="lineno">  728</span> </div>
<div class="line"><a id="l00729" name="l00729"></a><span class="lineno">  729</span>        <span class="comment">//evaluating the betas in every unit</span></div>
<div class="line"><a id="l00730" name="l00730"></a><span class="lineno">  730</span>        std::vector&lt; std::vector&lt;OUTPUT&gt; &gt; beta_j_ev;</div>
<div class="line"><a id="l00731" name="l00731"></a><span class="lineno">  731</span>        beta_j_ev.reserve(B[j].size());</div>
<div class="line"><a id="l00732" name="l00732"></a><span class="lineno">  732</span>        <span class="keywordflow">for</span>(std::size_t i = 0; i &lt; B[j].size(); ++i)</div>
<div class="line"><a id="l00733" name="l00733"></a><span class="lineno">  733</span>        {</div>
<div class="line"><a id="l00734" name="l00734"></a><span class="lineno">  734</span>            <span class="comment">//compute the beta j-th for unit i-th</span></div>
<div class="line"><a id="l00735" name="l00735"></a><span class="lineno">  735</span>            <a class="code hl_typedef" href="functional__matrix__storing__type_8hpp.html#a70bd7133abb8b1da57ebdefc24d861b0">FUNC_OBJ&lt;INPUT,OUTPUT&gt;</a> beta_j_i = <a class="code hl_function" href="functional__matrix__product_8hpp.html#aeb98bde348f8f5eb62e272fb771ce869">fm_prod&lt;INPUT,OUTPUT&gt;</a>(basis_j,B[j][i],m_number_threads)(0,0);</div>
<div class="line"><a id="l00736" name="l00736"></a><span class="lineno">  736</span>            <span class="comment">//eval the beta</span></div>
<div class="line"><a id="l00737" name="l00737"></a><span class="lineno">  737</span>            std::vector&lt; OUTPUT &gt; beta_j_i_ev; </div>
<div class="line"><a id="l00738" name="l00738"></a><span class="lineno">  738</span>            beta_j_i_ev.resize(abscissas.size());</div>
<div class="line"><a id="l00739" name="l00739"></a><span class="lineno">  739</span>            std::transform(abscissas.cbegin(),abscissas.cend(),beta_j_i_ev.begin(),[&amp;beta_j_i](F_OBJ_INPUT x){return beta_j_i(x);});</div>
<div class="line"><a id="l00740" name="l00740"></a><span class="lineno">  740</span>            beta_j_ev.push_back(beta_j_i_ev);</div>
<div class="line"><a id="l00741" name="l00741"></a><span class="lineno">  741</span>        }</div>
<div class="line"><a id="l00742" name="l00742"></a><span class="lineno">  742</span> </div>
<div class="line"><a id="l00743" name="l00743"></a><span class="lineno">  743</span>        beta.push_back(beta_j_ev);</div>
<div class="line"><a id="l00744" name="l00744"></a><span class="lineno">  744</span>    }</div>
<div class="line"><a id="l00745" name="l00745"></a><span class="lineno">  745</span> </div>
<div class="line"><a id="l00746" name="l00746"></a><span class="lineno">  746</span>    <span class="keywordflow">return</span> beta;</div>
<div class="line"><a id="l00747" name="l00747"></a><span class="lineno">  747</span>}</div>
</div>
<div class="line"><a id="l00748" name="l00748"></a><span class="lineno">  748</span></div>
<div class="line"><a id="l00756" name="l00756"></a><span class="lineno">  756</span><span class="keyword">template</span>&lt; <span class="keyword">typename</span> INPUT, <span class="keyword">typename</span> OUTPUT &gt;</div>
<div class="line"><a id="l00757" name="l00757"></a><span class="lineno">  757</span>    <span class="keyword">requires</span> (std::integral&lt;INPUT&gt; || std::floating_point&lt;INPUT&gt;)  &amp;&amp;  (std::integral&lt;OUTPUT&gt; || std::floating_point&lt;OUTPUT&gt;)</div>
<div class="line"><a id="l00758" name="l00758"></a><span class="lineno">  758</span>std::vector&lt; std::vector&lt;OUTPUT&gt; &gt;</div>
<div class="foldopen" id="foldopen00759" data-start="{" data-end="}">
<div class="line"><a id="l00759" name="l00759"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#a72e675a99e8c932900916ea64e1adaf2">  759</a></span><a class="code hl_function" href="classfwr__operator__computing.html#a7d3e3832d6fbac64669ab9e0d2a5f2ac">fwr_operator_computing&lt;INPUT,OUTPUT&gt;::eval_func_betas</a>(<span class="keyword">const</span> <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a> &amp;beta,</div>
<div class="line"><a id="l00760" name="l00760"></a><span class="lineno">  760</span>                                                      std::size_t q,</div>
<div class="line"><a id="l00761" name="l00761"></a><span class="lineno">  761</span>                                                      <span class="keyword">const</span> std::vector&lt;INPUT&gt; &amp;abscissa)<span class="keyword"> </span></div>
<div class="line"><a id="l00762" name="l00762"></a><span class="lineno">  762</span><span class="keyword">const</span></div>
<div class="line"><a id="l00763" name="l00763"></a><span class="lineno">  763</span><span class="keyword"></span>{</div>
<div class="line"><a id="l00764" name="l00764"></a><span class="lineno">  764</span>    <span class="comment">//input coherency</span></div>
<div class="line"><a id="l00765" name="l00765"></a><span class="lineno">  765</span>    assert((beta.<a class="code hl_function" href="classfunctional__matrix.html#a08e1da679d37d9974ed71301cd894b85">rows</a>() == q) &amp;&amp; (beta.<a class="code hl_function" href="classfunctional__matrix.html#ad428919ba1bce43d020af0eef595e223">cols</a>() == 1));</div>
<div class="line"><a id="l00766" name="l00766"></a><span class="lineno">  766</span>    <span class="comment">//number of evaluations</span></div>
<div class="line"><a id="l00767" name="l00767"></a><span class="lineno">  767</span>    std::size_t n_abs = abscissa.size();</div>
<div class="line"><a id="l00768" name="l00768"></a><span class="lineno">  768</span> </div>
<div class="line"><a id="l00769" name="l00769"></a><span class="lineno">  769</span>    <span class="comment">//reserving</span></div>
<div class="line"><a id="l00770" name="l00770"></a><span class="lineno">  770</span>    std::vector&lt; std::vector&lt;OUTPUT&gt;&gt; beta_ev;    </div>
<div class="line"><a id="l00771" name="l00771"></a><span class="lineno">  771</span>    beta_ev.reserve(q);        </div>
<div class="line"><a id="l00772" name="l00772"></a><span class="lineno">  772</span> </div>
<div class="line"><a id="l00773" name="l00773"></a><span class="lineno">  773</span>    <span class="keywordflow">for</span> (std::size_t j = 0; j &lt; q; ++j)</div>
<div class="line"><a id="l00774" name="l00774"></a><span class="lineno">  774</span>    {</div>
<div class="line"><a id="l00775" name="l00775"></a><span class="lineno">  775</span>        std::vector&lt;OUTPUT&gt; beta_j_ev;</div>
<div class="line"><a id="l00776" name="l00776"></a><span class="lineno">  776</span>        beta_j_ev.resize(n_abs);</div>
<div class="line"><a id="l00777" name="l00777"></a><span class="lineno">  777</span> </div>
<div class="line"><a id="l00778" name="l00778"></a><span class="lineno">  778</span><span class="preprocessor">#ifdef _OPENMP</span></div>
<div class="line"><a id="l00779" name="l00779"></a><span class="lineno">  779</span><span class="preprocessor">#pragma omp parallel for shared(beta_j_ev,j,abscissa,n_abs) num_threads(m_number_threads)</span></div>
<div class="line"><a id="l00780" name="l00780"></a><span class="lineno">  780</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l00781" name="l00781"></a><span class="lineno">  781</span>        <span class="keywordflow">for</span>(std::size_t i = 0; i &lt; n_abs; ++i)</div>
<div class="line"><a id="l00782" name="l00782"></a><span class="lineno">  782</span>        {</div>
<div class="line"><a id="l00783" name="l00783"></a><span class="lineno">  783</span>            beta_j_ev[i] = beta(j,0)(abscissa[i]);</div>
<div class="line"><a id="l00784" name="l00784"></a><span class="lineno">  784</span>        }</div>
<div class="line"><a id="l00785" name="l00785"></a><span class="lineno">  785</span> </div>
<div class="line"><a id="l00786" name="l00786"></a><span class="lineno">  786</span>        beta_ev.push_back(beta_j_ev);</div>
<div class="line"><a id="l00787" name="l00787"></a><span class="lineno">  787</span>    }</div>
<div class="line"><a id="l00788" name="l00788"></a><span class="lineno">  788</span> </div>
<div class="line"><a id="l00789" name="l00789"></a><span class="lineno">  789</span>    <span class="keywordflow">return</span> beta_ev;</div>
<div class="line"><a id="l00790" name="l00790"></a><span class="lineno">  790</span>}</div>
</div>
<div class="line"><a id="l00791" name="l00791"></a><span class="lineno">  791</span></div>
<div class="line"><a id="l00799" name="l00799"></a><span class="lineno">  799</span><span class="keyword">template</span>&lt; <span class="keyword">typename</span> INPUT, <span class="keyword">typename</span> OUTPUT &gt;</div>
<div class="line"><a id="l00800" name="l00800"></a><span class="lineno">  800</span>    <span class="keyword">requires</span> (std::integral&lt;INPUT&gt; || std::floating_point&lt;INPUT&gt;)  &amp;&amp;  (std::integral&lt;OUTPUT&gt; || std::floating_point&lt;OUTPUT&gt;)</div>
<div class="line"><a id="l00801" name="l00801"></a><span class="lineno">  801</span>std::vector&lt; std::vector&lt; std::vector&lt;OUTPUT&gt;&gt;&gt;</div>
<div class="foldopen" id="foldopen00802" data-start="{" data-end="}">
<div class="line"><a id="l00802" name="l00802"></a><span class="lineno"><a class="line" href="classfwr__operator__computing.html#a4f01e517f32329c8355b33d4f56505d9">  802</a></span><a class="code hl_function" href="classfwr__operator__computing.html#a7d3e3832d6fbac64669ab9e0d2a5f2ac">fwr_operator_computing&lt;INPUT,OUTPUT&gt;::eval_func_betas</a>(<span class="keyword">const</span> std::vector&lt; <a class="code hl_class" href="classfunctional__matrix.html">functional_matrix&lt;INPUT,OUTPUT&gt;</a>&gt; &amp;beta,</div>
<div class="line"><a id="l00803" name="l00803"></a><span class="lineno">  803</span>                                                      std::size_t q,</div>
<div class="line"><a id="l00804" name="l00804"></a><span class="lineno">  804</span>                                                      <span class="keyword">const</span> std::vector&lt;INPUT&gt; &amp;abscissa)<span class="keyword"></span></div>
<div class="line"><a id="l00805" name="l00805"></a><span class="lineno">  805</span><span class="keyword">const</span></div>
<div class="line"><a id="l00806" name="l00806"></a><span class="lineno">  806</span><span class="keyword"></span>{</div>
<div class="line"><a id="l00807" name="l00807"></a><span class="lineno">  807</span>    std::size_t n_pred = beta.size();</div>
<div class="line"><a id="l00808" name="l00808"></a><span class="lineno">  808</span>    std::size_t n_abs  = abscissa.size();</div>
<div class="line"><a id="l00809" name="l00809"></a><span class="lineno">  809</span>    <span class="comment">//input coherency</span></div>
<div class="line"><a id="l00810" name="l00810"></a><span class="lineno">  810</span>    <span class="keywordflow">for</span>(std::size_t i = 0; i &lt; n_pred; ++i){    assert((beta[i].rows() == q) &amp;&amp; (beta[i].cols() == 1));}</div>
<div class="line"><a id="l00811" name="l00811"></a><span class="lineno">  811</span>    </div>
<div class="line"><a id="l00812" name="l00812"></a><span class="lineno">  812</span> </div>
<div class="line"><a id="l00813" name="l00813"></a><span class="lineno">  813</span>    <span class="comment">//reserving</span></div>
<div class="line"><a id="l00814" name="l00814"></a><span class="lineno">  814</span>    std::vector&lt; std::vector&lt; std::vector&lt;OUTPUT&gt;&gt; &gt; beta_ev;    </div>
<div class="line"><a id="l00815" name="l00815"></a><span class="lineno">  815</span>    beta_ev.reserve(q);  </div>
<div class="line"><a id="l00816" name="l00816"></a><span class="lineno">  816</span>    </div>
<div class="line"><a id="l00817" name="l00817"></a><span class="lineno">  817</span>    <span class="keywordflow">for</span>(std::size_t j = 0; j &lt; q; ++j)</div>
<div class="line"><a id="l00818" name="l00818"></a><span class="lineno">  818</span>    {</div>
<div class="line"><a id="l00819" name="l00819"></a><span class="lineno">  819</span>        std::vector&lt; std::vector&lt;OUTPUT&gt;&gt; beta_j_ev;</div>
<div class="line"><a id="l00820" name="l00820"></a><span class="lineno">  820</span>        beta_j_ev.reserve(n_pred);</div>
<div class="line"><a id="l00821" name="l00821"></a><span class="lineno">  821</span> </div>
<div class="line"><a id="l00822" name="l00822"></a><span class="lineno">  822</span>        <span class="keywordflow">for</span>(std::size_t i = 0; i &lt; n_pred; ++i)</div>
<div class="line"><a id="l00823" name="l00823"></a><span class="lineno">  823</span>        {</div>
<div class="line"><a id="l00824" name="l00824"></a><span class="lineno">  824</span>            std::vector&lt;OUTPUT&gt; beta_j_i_ev;</div>
<div class="line"><a id="l00825" name="l00825"></a><span class="lineno">  825</span>            beta_j_i_ev.resize(n_abs);</div>
<div class="line"><a id="l00826" name="l00826"></a><span class="lineno">  826</span> </div>
<div class="line"><a id="l00827" name="l00827"></a><span class="lineno">  827</span><span class="preprocessor">#ifdef _OPENMP</span></div>
<div class="line"><a id="l00828" name="l00828"></a><span class="lineno">  828</span><span class="preprocessor">#pragma omp parallel for shared(beta_j_i_ev,j,i,abscissa,n_abs) num_threads(m_number_threads)</span></div>
<div class="line"><a id="l00829" name="l00829"></a><span class="lineno">  829</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l00830" name="l00830"></a><span class="lineno">  830</span>            <span class="keywordflow">for</span>(std::size_t i_ev = 0; i_ev &lt; n_abs; ++i_ev)</div>
<div class="line"><a id="l00831" name="l00831"></a><span class="lineno">  831</span>            {</div>
<div class="line"><a id="l00832" name="l00832"></a><span class="lineno">  832</span>                beta_j_i_ev[i_ev] = beta[i](j,0)(abscissa[i_ev]);</div>
<div class="line"><a id="l00833" name="l00833"></a><span class="lineno">  833</span>            }</div>
<div class="line"><a id="l00834" name="l00834"></a><span class="lineno">  834</span> </div>
<div class="line"><a id="l00835" name="l00835"></a><span class="lineno">  835</span>            beta_j_ev.push_back(beta_j_i_ev);</div>
<div class="line"><a id="l00836" name="l00836"></a><span class="lineno">  836</span>        }</div>
<div class="line"><a id="l00837" name="l00837"></a><span class="lineno">  837</span> </div>
<div class="line"><a id="l00838" name="l00838"></a><span class="lineno">  838</span>        beta_ev.push_back(beta_j_ev);</div>
<div class="line"><a id="l00839" name="l00839"></a><span class="lineno">  839</span>    }</div>
<div class="line"><a id="l00840" name="l00840"></a><span class="lineno">  840</span> </div>
<div class="line"><a id="l00841" name="l00841"></a><span class="lineno">  841</span>    <span class="keywordflow">return</span> beta_ev;</div>
<div class="line"><a id="l00842" name="l00842"></a><span class="lineno">  842</span>}</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="ttc" id="aclassfunctional__matrix__diagonal_html"><div class="ttname"><a href="classfunctional__matrix__diagonal.html">functional_matrix_diagonal</a></div><div class="ttdoc">Class for diagonal matrices storing univariate 1D domain std::function objects.</div><div class="ttdef"><b>Definition</b> functional_matrix_diagonal.hpp:49</div></div>
<div class="ttc" id="aclassfunctional__matrix__sparse_html"><div class="ttname"><a href="classfunctional__matrix__sparse.html">functional_matrix_sparse</a></div><div class="ttdoc">Class for sparse matrices storing, column-wise, in compress format (CSC), univariate 1D domain std::f...</div><div class="ttdef"><b>Definition</b> functional_matrix_sparse.hpp:55</div></div>
<div class="ttc" id="aclassfunctional__matrix__sparse_html_a2e658bd50a637ceab3a30ad7391ccf33"><div class="ttname"><a href="classfunctional__matrix__sparse.html#a2e658bd50a637ceab3a30ad7391ccf33">functional_matrix_sparse::rows</a></div><div class="ttdeci">std::size_t rows() const</div><div class="ttdoc">Rows size.</div><div class="ttdef"><b>Definition</b> functional_matrix_sparse.hpp:348</div></div>
<div class="ttc" id="aclassfunctional__matrix__sparse_html_a6cc0a36229ea306b7977158390d7b54a"><div class="ttname"><a href="classfunctional__matrix__sparse.html#a6cc0a36229ea306b7977158390d7b54a">functional_matrix_sparse::cols</a></div><div class="ttdeci">std::size_t cols() const</div><div class="ttdoc">Cols size.</div><div class="ttdef"><b>Definition</b> functional_matrix_sparse.hpp:359</div></div>
<div class="ttc" id="aclassfunctional__matrix_html"><div class="ttname"><a href="classfunctional__matrix.html">functional_matrix</a></div><div class="ttdoc">Class for dense matrices storing, column-wise, univariate 1D domain std::function objects.</div><div class="ttdef"><b>Definition</b> functional_matrix.hpp:56</div></div>
<div class="ttc" id="aclassfunctional__matrix_html_a08e1da679d37d9974ed71301cd894b85"><div class="ttname"><a href="classfunctional__matrix.html#a08e1da679d37d9974ed71301cd894b85">functional_matrix::rows</a></div><div class="ttdeci">std::size_t rows() const</div><div class="ttdoc">Rows size.</div><div class="ttdef"><b>Definition</b> functional_matrix.hpp:218</div></div>
<div class="ttc" id="aclassfunctional__matrix_html_a0e1dff48be43aa434b76de3b9ab237fc"><div class="ttname"><a href="classfunctional__matrix.html#a0e1dff48be43aa434b76de3b9ab237fc">functional_matrix::row_sub</a></div><div class="ttdeci">void row_sub(const std::vector&lt; F_OBJ &gt; &amp;new_row, std::size_t idx)</div><div class="ttdoc">Substituting the idx-th row.</div><div class="ttdef"><b>Definition</b> functional_matrix.hpp:308</div></div>
<div class="ttc" id="aclassfunctional__matrix_html_a2fe5a9c6e60487aa2939b40bf0a92b6f"><div class="ttname"><a href="classfunctional__matrix.html#a2fe5a9c6e60487aa2939b40bf0a92b6f">functional_matrix::row</a></div><div class="ttdeci">RowXpr row(std::size_t idx)</div><div class="ttdoc">View of the idx-th row, non-const.</div><div class="ttdef"><b>Definition</b> functional_matrix.hpp:262</div></div>
<div class="ttc" id="aclassfunctional__matrix_html_a5a9eb8cced9b3dd9a83b98982aa8cf55"><div class="ttname"><a href="classfunctional__matrix.html#a5a9eb8cced9b3dd9a83b98982aa8cf55">functional_matrix::as_vector</a></div><div class="ttdeci">std::vector&lt; F_OBJ &gt; const &amp; as_vector() const</div><div class="ttdoc">Casting to a std::vector &amp;, const version.</div><div class="ttdef"><b>Definition</b> functional_matrix.hpp:427</div></div>
<div class="ttc" id="aclassfunctional__matrix_html_ad428919ba1bce43d020af0eef595e223"><div class="ttname"><a href="classfunctional__matrix.html#ad428919ba1bce43d020af0eef595e223">functional_matrix::cols</a></div><div class="ttdeci">std::size_t cols() const</div><div class="ttdoc">Columns size.</div><div class="ttdef"><b>Definition</b> functional_matrix.hpp:229</div></div>
<div class="ttc" id="aclassfwr__operator__computing_html_a0f9fba8f012107fd443b687ba90b9886"><div class="ttname"><a href="classfwr__operator__computing.html#a0f9fba8f012107fd443b687ba90b9886">fwr_operator_computing::wrap_operator</a></div><div class="ttdeci">std::vector&lt; FDAGWR_TRAITS::Dense_Matrix &gt; wrap_operator(const FDAGWR_TRAITS::Dense_Matrix &amp;b, const std::vector&lt; std::size_t &gt; &amp;L_j, std::size_t q) const</div><div class="ttdoc">For stationary covariates, wrap the basis expansion coefficients of the functional regression coeffic...</div><div class="ttdef"><b>Definition</b> fwr_operator_computing_imp.hpp:507</div></div>
<div class="ttc" id="aclassfwr__operator__computing_html_a20202c6ca2e008c6f37014232c9d8506"><div class="ttname"><a href="classfwr__operator__computing.html#a20202c6ca2e008c6f37014232c9d8506">fwr_operator_computing::compute_operator</a></div><div class="ttdeci">std::vector&lt; FDAGWR_TRAITS::Dense_Matrix &gt; compute_operator(const functional_matrix_sparse&lt; INPUT, OUTPUT &gt; &amp;base_lhs, const functional_matrix&lt; INPUT, OUTPUT &gt; &amp;X_lhs, const std::vector&lt; functional_matrix_diagonal&lt; INPUT, OUTPUT &gt; &gt; &amp;W, const functional_matrix&lt; INPUT, OUTPUT &gt; &amp;X_rhs, const functional_matrix_sparse&lt; INPUT, OUTPUT &gt; &amp;base_rhs, const std::vector&lt; Eigen::PartialPivLU&lt; FDAGWR_TRAITS::Dense_Matrix &gt; &gt; &amp;penalty) const</div><div class="ttdoc">Compute a scalar (matrix) operator as, for each unit [J_i + R]^(-1) * int_a_b(base_lhs * X_lhs * W_i ...</div><div class="ttdef"><b>Definition</b> fwr_operator_computing_imp.hpp:189</div></div>
<div class="ttc" id="aclassfwr__operator__computing_html_a2b15bc86a2d8daaef9934398adcd7116"><div class="ttname"><a href="classfwr__operator__computing.html#a2b15bc86a2d8daaef9934398adcd7116">fwr_operator_computing::compute_functional_operator</a></div><div class="ttdeci">functional_matrix&lt; INPUT, OUTPUT &gt; compute_functional_operator(const functional_matrix&lt; INPUT, OUTPUT &gt; &amp;X, const functional_matrix_sparse&lt; INPUT, OUTPUT &gt; &amp;base, const std::vector&lt; FDAGWR_TRAITS::Dense_Matrix &gt; &amp;_operator_) const</div><div class="ttdoc">Compute a functional operator, intended as a matrix where: each row is the respective row of the func...</div><div class="ttdef"><b>Definition</b> fwr_operator_computing_imp.hpp:469</div></div>
<div class="ttc" id="aclassfwr__operator__computing_html_a634f00fe47b21671fb008f732eb7ec89"><div class="ttname"><a href="classfwr__operator__computing.html#a634f00fe47b21671fb008f732eb7ec89">fwr_operator_computing::compute_penalty</a></div><div class="ttdeci">std::vector&lt; Eigen::PartialPivLU&lt; FDAGWR_TRAITS::Dense_Matrix &gt; &gt; compute_penalty(const functional_matrix_sparse&lt; INPUT, OUTPUT &gt; &amp;base_t, const functional_matrix&lt; INPUT, OUTPUT &gt; &amp;X_t, const std::vector&lt; functional_matrix_diagonal&lt; INPUT, OUTPUT &gt; &gt; &amp;W, const functional_matrix&lt; INPUT, OUTPUT &gt; &amp;X, const functional_matrix_sparse&lt; INPUT, OUTPUT &gt; &amp;base, const FDAGWR_TRAITS::Sparse_Matrix &amp;R) const</div><div class="ttdoc">Compute [J_i + R]^(-1), where, for each unit i-th:</div><div class="ttdef"><b>Definition</b> fwr_operator_computing_imp.hpp:47</div></div>
<div class="ttc" id="aclassfwr__operator__computing_html_a7d3e3832d6fbac64669ab9e0d2a5f2ac"><div class="ttname"><a href="classfwr__operator__computing.html#a7d3e3832d6fbac64669ab9e0d2a5f2ac">fwr_operator_computing::eval_func_betas</a></div><div class="ttdeci">std::vector&lt; std::vector&lt; OUTPUT &gt; &gt; eval_func_betas(const std::vector&lt; FDAGWR_TRAITS::Dense_Matrix &gt; &amp;B, const functional_matrix_sparse&lt; INPUT, OUTPUT &gt; &amp;basis_B, const std::vector&lt; std::size_t &gt; &amp;L_j, std::size_t q, const std::vector&lt; INPUT &gt; &amp;abscissas) const</div><div class="ttdoc">Evaluation the stationary betas, as basis expansion coefficients and basis, over a grid of points.</div><div class="ttdef"><b>Definition</b> fwr_operator_computing_imp.hpp:644</div></div>
<div class="ttc" id="aclassfwr__operator__computing_html_ab63b635a1edc829c2652e54a66f446b2"><div class="ttname"><a href="classfwr__operator__computing.html#ab63b635a1edc829c2652e54a66f446b2">fwr_operator_computing::dewrap_operator</a></div><div class="ttdeci">FDAGWR_TRAITS::Dense_Matrix dewrap_operator(const std::vector&lt; FDAGWR_TRAITS::Dense_Matrix &gt; &amp;b, const std::vector&lt; std::size_t &gt; &amp;L_j) const</div><div class="ttdoc">For stationary covariates, dewrap the basis expansion coefficients for functional regression coeffici...</div><div class="ttdef"><b>Definition</b> fwr_operator_computing_imp.hpp:579</div></div>
<div class="ttc" id="afunctional__matrix__product_8hpp_html_aeb98bde348f8f5eb62e272fb771ce869"><div class="ttname"><a href="functional__matrix__product_8hpp.html#aeb98bde348f8f5eb62e272fb771ce869">fm_prod</a></div><div class="ttdeci">functional_matrix&lt; INPUT, OUTPUT &gt; fm_prod(const functional_matrix&lt; INPUT, OUTPUT &gt; &amp;M1, const functional_matrix&lt; INPUT, OUTPUT &gt; &amp;M2, int number_threads)</div><div class="ttdoc">Matrix product within two functional matrices M1*M2.</div><div class="ttdef"><b>Definition</b> functional_matrix_product.hpp:63</div></div>
<div class="ttc" id="afunctional__matrix__storing__type_8hpp_html_a70bd7133abb8b1da57ebdefc24d861b0"><div class="ttname"><a href="functional__matrix__storing__type_8hpp.html#a70bd7133abb8b1da57ebdefc24d861b0">FUNC_OBJ</a></div><div class="ttdeci">std::function&lt; OUTPUT(INPUT const &amp;) &gt; FUNC_OBJ</div><div class="ttdoc">univariate 1D domain std::function object stored in a functional_matrix</div><div class="ttdef"><b>Definition</b> functional_matrix_storing_type.hpp:46</div></div>
<div class="ttc" id="afwr__operator__computing_8hpp_html"><div class="ttname"><a href="fwr__operator__computing_8hpp.html">fwr_operator_computing.hpp</a></div><div class="ttdoc">Contains the class for computing operators needed in FWR, wrapping and dewrapping the basis expansion...</div></div>
<div class="ttc" id="anamespacefm__utils_html_a748f7d067be88eb04e84183231471d39"><div class="ttname"><a href="namespacefm__utils.html#a748f7d067be88eb04e84183231471d39">fm_utils::input_param_t</a></div><div class="ttdeci">typename function_traits&lt; F &gt;::input_param_type input_param_t</div><div class="ttdoc">extracting the type of the input in the callable object F, considering eventual const references</div><div class="ttdef"><b>Definition</b> functional_matrix_utils.hpp:128</div></div>
<div class="ttc" id="astruct_f_d_a_g_w_r___t_r_a_i_t_s_html_a3c0ac6887d94bffa71939fba3c05fb98"><div class="ttname"><a href="struct_f_d_a_g_w_r___t_r_a_i_t_s.html#a3c0ac6887d94bffa71939fba3c05fb98">FDAGWR_TRAITS::Sparse_Matrix</a></div><div class="ttdeci">Eigen::SparseMatrix&lt; double &gt; Sparse_Matrix</div><div class="ttdoc">Sparse matrix data structure.</div><div class="ttdef"><b>Definition</b> traits_fdagwr.hpp:47</div></div>
<div class="ttc" id="astruct_f_d_a_g_w_r___t_r_a_i_t_s_html_a7480032013388cae40a69abf8d4ba297"><div class="ttname"><a href="struct_f_d_a_g_w_r___t_r_a_i_t_s.html#a7480032013388cae40a69abf8d4ba297">FDAGWR_TRAITS::Dense_Matrix</a></div><div class="ttdeci">Eigen::MatrixXd Dense_Matrix</div><div class="ttdoc">Matrix data structure.</div><div class="ttdef"><b>Definition</b> traits_fdagwr.hpp:45</div></div>
<div class="ttc" id="astruct_row_view_html_a31a3024f41d57c24b1449787b120e535"><div class="ttname"><a href="struct_row_view.html#a31a3024f41d57c24b1449787b120e535">RowView::cbegin</a></div><div class="ttdeci">StridedIterator&lt; const T * &gt; cbegin() const</div><div class="ttdoc">Getter for the start of the row, const verion.</div><div class="ttdef"><b>Definition</b> functional_matrix_views.hpp:133</div></div>
<div class="ttc" id="astruct_row_view_html_abdcaf65a4f67f136927a95951f056d69"><div class="ttname"><a href="struct_row_view.html#abdcaf65a4f67f136927a95951f056d69">RowView::cend</a></div><div class="ttdeci">StridedIterator&lt; const T * &gt; cend() const</div><div class="ttdoc">Getter for the end of the row, const verion.</div><div class="ttdef"><b>Definition</b> functional_matrix_views.hpp:139</div></div>
</div><!-- fragment --></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="dir_68267d1309a1af8e8297ef4c3efbcdba.html">src</a></li><li class="navelem"><a class="el" href="dir_244c8005de582a528838264aad662148.html">integration</a></li><li class="navelem"><a class="el" href="fwr__operator__computing__imp_8hpp.html">fwr_operator_computing_imp.hpp</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.13.1 </li>
  </ul>
</div>
</body>
</html>
